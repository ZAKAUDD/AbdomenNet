{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dataset in global_vars.py to NAKO.\n",
    "from global_vars import *\n",
    "from commons import *\n",
    "\n",
    "import glob \n",
    "import os\n",
    "\n",
    "one_time_n4_optimization = True\n",
    "vol_to_check_list = None #['100025']\n",
    "exclude = ['100006', '100008']  # No SPleen\n",
    "# 181\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100008': {'VOLUME_PATHS': {'OPP': ['/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_1.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_2.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_3.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_4.nii.gz'],\n",
       "   'IN': ['/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_1_e2.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_2_e2.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_3_e2.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_4_e2.nii.gz'],\n",
       "   'F': ['/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_1.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_2.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_3.nii.gz',\n",
       "    '/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_4.nii.gz'],\n",
       "   'W': ['/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_2.nii.gz']},\n",
       "  'LABEL_PATHS': ['datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_2_Adrenal gland (left).nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_2-2.nrrd_Spleen-5.nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_2_Gallbladder (1).nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_2_Adrenal gland (right).nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/10008_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_subcutan fat.nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_2_Kidney (right) (1).nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_1_Thyroid gland.nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_2_Kidney(left)-4.nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_2_Pancreas-3.nrrd',\n",
       "   'datasets/lablmaps/NAKO/100008/100008_3D_GRE_TRA_opp_3D_GRE_TRA_2_Liver.nrrd']}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_nako_file_paths(load_from_txt_file=True):\n",
    "    volumes_to_use = []\n",
    "    if load_from_txt_file:\n",
    "        with open(volume_txt_file) as file_handle:\n",
    "                volumes_to_use = file_handle.read().splitlines()\n",
    "    else:\n",
    "        volumes_to_use = [name for name in os.listdir(data_dir)]\n",
    "    \n",
    "    file_paths = {}\n",
    "    \n",
    "    for vol in volumes_to_use:\n",
    "#         if vol != '100008':\n",
    "#             continue\n",
    "        if (vol_to_check_list is not None and vol not in vol_to_check_list) or (vol == \"\") or (vol in exclude):\n",
    "            continue\n",
    "        opp_paths = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_opp/**.nii.gz') # **_2**\n",
    "        in_paths = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_in/**.nii.gz')\n",
    "        f_paths = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_F/**.nii.gz')\n",
    "        w_paths = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_W/**.nii.gz')\n",
    "        \n",
    "        labelmap_paths = glob.glob(f'{label_dir}/{vol}/**')\n",
    "        \n",
    "        vol_madals_paths = dict(\n",
    "        OPP=opp_paths,\n",
    "        IN=in_paths,\n",
    "        F=f_paths,\n",
    "        W=w_paths\n",
    "        )\n",
    "        file_paths[str(vol)]=dict(\n",
    "            VOLUME_PATHS=vol_madals_paths,\n",
    "            LABEL_PATHS=labelmap_paths,\n",
    "        )\n",
    "    return file_paths\n",
    "\n",
    "file_paths = load_nako_file_paths()\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob.glob(f'{data_dir}/{vol}/**/**.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vol = '100008'\n",
    "# a = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_W/**.nii.gz')\n",
    "# volume_3_view_viewer(get_volume_data(nb.load('/mnt/nas/Data_WholeBody/NAKO/NAKO_200/MRI/100008/100008_3D_GRE_TRA_W_COMPOSED/3D_GRE_TRA_W_COMPOSED_-23_3D_GRE_TRA_4_e2.nii.gz')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual RESCALING.\n",
    "n4_dict = {}\n",
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4 processing part-1 started with {vol}...')\n",
    "    n4_dict[vol] = []\n",
    "    vol_parts = [[file, read_ras(file)] for file in file_paths[vol]['VOLUME_PATHS']['IN']]\n",
    "    for orig_file, in_image in vol_parts:\n",
    "        n4_dict[vol].append(rescale(in_image, vol, orig_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITK does ot work due to differences in pixel resolution of IN and corresponding OPP Scan.\n",
    "# Only applying once at the end.\n",
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4-biasfield-correction starting with {vol}...')\n",
    "    for idx, n4_d in enumerate(n4_dict[vol]):\n",
    "        in_file = n4_d['SCALED']\n",
    "        opp_file = file_paths[vol]['VOLUME_PATHS']['OPP'][idx]\n",
    "        new_filename = opp_file.split('/')[-1].split('.')[0]\n",
    "        output_file = f'{n4_corrected_data_dir}/vol/{vol}/{new_filename}_n4_corrected_sitk.nii.gz'\n",
    "        SITK_N4_normalization(in_file, opp_file, output_file)\n",
    "        n4_dict[vol][idx]['OPP_CORRECTED'] = output_file\n",
    "\n",
    "    file_paths[vol]['N4_1'] = n4_dict[vol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started with 100008...\n",
      "processing OPP\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -384.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -576.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -804.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[ 1.40625000e+00  0.00000000e+00  0.00000000e+00 -2.31093750e+02]\n",
      " [ 0.00000000e+00  1.40625000e+00  0.00000000e+00 -2.14435913e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  3.00000000e+00 -1.04476697e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "0th img for stitching...\n",
      "1th img for stitching...\n",
      "2th img for stitching...\n",
      "[[ 2.00000000e+00  0.00000000e+00  0.00000000e+00 -2.31093750e+02]\n",
      " [ 0.00000000e+00  2.00000000e+00  0.00000000e+00 -2.14435913e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  3.00000000e+00 -1.04476697e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/n4_corrected_2/vol/100008\n",
      "processing IN\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -384.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -576.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -804.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[ 1.40625000e+00  0.00000000e+00  0.00000000e+00 -2.31093750e+02]\n",
      " [ 0.00000000e+00  1.40625000e+00  0.00000000e+00 -2.14435913e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  3.00000000e+00 -1.04476697e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "0th img for stitching...\n",
      "1th img for stitching...\n",
      "2th img for stitching...\n",
      "[[ 2.00000000e+00  0.00000000e+00  0.00000000e+00 -2.31093750e+02]\n",
      " [ 0.00000000e+00  2.00000000e+00  0.00000000e+00 -2.14435913e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  3.00000000e+00 -1.04476697e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/n4_corrected_2/vol/100008\n",
      "processing F\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -384.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -576.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -804.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[ 1.40625000e+00  0.00000000e+00  0.00000000e+00 -2.31093750e+02]\n",
      " [ 0.00000000e+00  1.40625000e+00  0.00000000e+00 -2.14435913e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  3.00000000e+00 -1.04476697e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "0th img for stitching...\n",
      "1th img for stitching...\n",
      "2th img for stitching...\n",
      "[[ 2.00000000e+00  0.00000000e+00  0.00000000e+00 -2.31093750e+02]\n",
      " [ 0.00000000e+00  2.00000000e+00  0.00000000e+00 -2.14435913e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  3.00000000e+00 -1.04476697e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/n4_corrected_2/vol/100008\n",
      "processing W\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625       0.            0.         -231.09375   ]\n",
      " [   0.            1.40625       0.         -214.43591309]\n",
      " [   0.            0.            3.         -576.76696777]\n",
      " [   0.            0.            0.            1.        ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "[[   2.            0.            0.         -231.09375   ]\n",
      " [   0.            2.            0.         -214.43591309]\n",
      " [   0.            0.            3.         -576.76696777]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/n4_corrected_2/vol/100008\n"
     ]
    }
   ],
   "source": [
    "# STITCHING VOL PARTS HERE\n",
    "for vol in file_paths.keys():\n",
    "    try:\n",
    "        print(f'started with {vol}...')\n",
    "        if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "            continue\n",
    "#         if vol not in ['100112']:\n",
    "#             continue\n",
    "        create_if_not(f'{n4_corrected_data_dir}/vol/{vol}')\n",
    "        file_paths[vol]['ONE'] = {}\n",
    "        for modality_key in file_paths[vol]['VOLUME_PATHS'].keys():\n",
    "            print(f\"processing {modality_key}\")\n",
    "            orig_modal_key = modality_key\n",
    "            if one_time_n4_optimization:\n",
    "                vol_parts = [read_ras(file) for file in file_paths[vol]['VOLUME_PATHS'][modality_key]]\n",
    "            else:\n",
    "                if modality_key == 'OPP':\n",
    "                    vol_parts = [read_ras(data_dict['OPP_CORRECTED']) for data_dict in file_paths[vol]['N4_1']]\n",
    "                    modality_key = modality_key+'_n4_corrected'\n",
    "                else:\n",
    "                    vol_parts = [read_ras(file) for file in file_paths[vol]['VOLUME_PATHS'][modality_key]]\n",
    "\n",
    "            ras_stitched = multi_vol_stitching(vol_parts)\n",
    "            save_volume(ras_stitched, f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched')\n",
    "            file_paths[vol]['ONE'][f'{orig_modal_key}'] = f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched.nii.gz'\n",
    "    except Exception as e:\n",
    "        print('ERROR:',e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESCALING INTENSITIES OF STITCHED VOLUME ABOVE 0\n",
    "n4_dict = {}\n",
    "for vol in file_paths.keys():\n",
    "    try:\n",
    "        if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "            continue\n",
    "#         if vol not in ['100112']:\n",
    "#             continue\n",
    "        print(f'n4 processing part-2 started with {vol}...')\n",
    "        n4_dict[vol] = {}\n",
    "        in_stitched_file_path, in_stitched_img = file_paths[vol]['ONE']['IN'], read_ras(file_paths[vol]['ONE']['IN'])\n",
    "        n4_dict[vol]['N4_2'] = rescale(in_stitched_img, vol, in_stitched_file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('ERROR:',e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_n4_process = True\n",
    "for vol in file_paths.keys():\n",
    "    try:\n",
    "        if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "            continue\n",
    "#         if vol not in [ '100112']:\n",
    "#             continue\n",
    "        print(f'n4-biasfield-correction starting with {vol}...')\n",
    "        in_file = n4_dict[vol]['N4_2']['SCALED']\n",
    "        opp_file = file_paths[vol]['ONE']['OPP']\n",
    "        if all_n4_process:\n",
    "            w_file = file_paths[vol]['ONE']['W']\n",
    "            w_of = w_file.split('/')[-1].split('.')[0]\n",
    "            w_outputfile = f'{n4_corrected_data_dir}/vol/{vol}/{w_of}_n4_corrected_sitk.nii.gz'\n",
    "            SITK_N4_normalization(in_file, w_file, w_outputfile)\n",
    "            n4_dict[vol]['N4_2']['W_CORRECTED'] = w_outputfile\n",
    "            \n",
    "            f_file = file_paths[vol]['ONE']['F']\n",
    "            f_of = f_file.split('/')[-1].split('.')[0]\n",
    "            f_outputfile = f'{n4_corrected_data_dir}/vol/{vol}/{f_of}_n4_corrected_sitk.nii.gz'\n",
    "            SITK_N4_normalization(in_file, f_file, f_outputfile)\n",
    "            n4_dict[vol]['N4_2']['F_CORRECTED'] = f_outputfile\n",
    "            \n",
    "            inin_file = file_paths[vol]['ONE']['IN']\n",
    "            in_of = inin_file.split('/')[-1].split('.')[0]\n",
    "            in_outputfile = f'{n4_corrected_data_dir}/vol/{vol}/{in_of}_n4_corrected_sitk.nii.gz'\n",
    "            SITK_N4_normalization(in_file, inin_file, in_outputfile)\n",
    "            n4_dict[vol]['N4_2']['IN_CORRECTED'] = in_outputfile\n",
    "        new_filename = opp_file.split('/')[-1].split('.')[0]\n",
    "        output_file = f'{n4_corrected_data_dir}/vol/{vol}/{new_filename}_n4_corrected_sitk.nii.gz'\n",
    "        SITK_N4_normalization(in_file, opp_file, output_file)\n",
    "        n4_dict[vol]['N4_2']['OPP_CORRECTED'] = output_file\n",
    "        file_paths[vol]['N4_2'] = n4_dict[vol]['N4_2']\n",
    "    except Exception as e:\n",
    "        print('ERROR:',e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nako_vol_label_fix(vol, label):\n",
    "    world_shape = np.max(np.array([list(vol.shape), list(label.shape)]), axis=0)\n",
    "    final_label = np.zeros(tuple(world_shape))\n",
    "\n",
    "    label_affine = label.affine\n",
    "    vol_affine = vol.affine\n",
    "    \n",
    "    target_affine = vol_affine\n",
    "    target_header = vol.header\n",
    "    target_dim_v = vol.shape\n",
    "\n",
    "    sx,sy,sz,ex,ey,ez = np.abs(get_points(label, vol))\n",
    "    \n",
    "    final_label[0:ex+sx, 0:ey+sy, sz:ez] = label.get_fdata()\n",
    "    \n",
    "    final_label = np.flip(final_label, axis=0)\n",
    "    final_label = np.flip(final_label, axis=1)\n",
    "    \n",
    "    final_label_img = nb.Nifti1Image(final_label, target_affine, target_header)\n",
    "    return vol, final_label_img\n",
    "\n",
    "def nako_label_parts(label_parts, reference_labelmap=None):\n",
    "    stitched_label = None\n",
    "    mode = 'constant'\n",
    "    order = 0\n",
    "    if reference_labelmap is None:\n",
    "        label_shape = get_freequent_shape([img.shape for img, _, _ in label_parts])\n",
    "        reference_labelmap = [img for img, _, _ in label_parts if list(img.shape) == list(label_shape)][0]\n",
    "    else:\n",
    "        label_shape = reference_labelmap.shape\n",
    "\n",
    "    stitched_label = np.zeros(label_shape)\n",
    "    for labelmap_img, lidx, lname in label_parts:\n",
    "        print(lidx, lname)\n",
    "        labelmap_img = makeit_3d(labelmap_img)\n",
    "        labelmap_img = resample_from_to(labelmap_img, [label_shape, reference_labelmap.affine], order=order, mode=mode, cval=0)\n",
    "        \n",
    "        sx,sy,sz,ex,ey,ez = np.abs(get_points(labelmap_img, reference_labelmap))\n",
    "        \n",
    "        labelmap = labelmap_img.get_fdata()\n",
    "        labelmap = np.multiply(lidx, labelmap)\n",
    "        stitched_label[0:ex+sx, 0:ey+sy, 0:ez+sz] += labelmap\n",
    "        \n",
    "        print(\"###############################################################################################\") \n",
    "        \n",
    "    labelmap = np.round(stitched_label)\n",
    "    stitched_labeled_img = nb.Nifti1Image(labelmap, reference_labelmap.affine, reference_labelmap.header)\n",
    "    \n",
    "    return stitched_labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STARTING NAKO LABEL-MAPS.\")\n",
    "print('Reading Label Maps.....')\n",
    "flag = True\n",
    "for vol in file_paths.keys():\n",
    "    print(vol)\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "#     if vol == '100083':\n",
    "#         flag = False\n",
    "#     if flag:\n",
    "#         continue\n",
    "    later = []\n",
    "    print(file_paths[vol]['LABEL_PATHS'])\n",
    "    if len(file_paths[vol]['LABEL_PATHS']) == 0:\n",
    "        print(f\"#################### ALERT:: NO LABELPATHS IN THE DICTIONARY FOR {vol} #########################\")\n",
    "        continue\n",
    "    volume = nb.load(file_paths[vol]['N4_2']['OPP_CORRECTED'])\n",
    "    f_volume = nb.load(file_paths[vol]['N4_2']['F_CORRECTED'])\n",
    "    w_volume = nb.load(file_paths[vol]['N4_2']['W_CORRECTED'])\n",
    "    in_volume = nb.load(file_paths[vol]['N4_2']['IN_CORRECTED'])\n",
    "#     volume = nb.load(file_paths[vol]['ONE']['OPP'])\n",
    "    img_ras_list = []\n",
    "    for label_file_to_read in file_paths[vol]['LABEL_PATHS']:\n",
    "        img_ras, lidx, labelname = read_ras(label_file_to_read, is_label=True)\n",
    "        if labelname is None or img_ras is None:\n",
    "            continue\n",
    "        img_ras = makeit_3d(img_ras)\n",
    "        img_ras = resample_to_output(img_ras, TARGET_RESOLUTION, order=0, mode='constant', cval=0)\n",
    "        if labelname == 'SPLEEN':\n",
    "            later.append([img_ras, lidx+LABEL_EXTENSION_FOR_OVERLAP_REMOVAL, labelname])\n",
    "        else:\n",
    "            img_ras_list.append([img_ras, lidx+LABEL_EXTENSION_FOR_OVERLAP_REMOVAL, labelname])\n",
    "    \n",
    "    img_ras_list.extend(later)\n",
    "    \n",
    "    s_label = nako_label_parts(img_ras_list)\n",
    "    s_label = drop_overlapped_pixels(s_label, np.array(img_ras_list)[:, 1])\n",
    "    volume, s_label = nako_vol_label_fix(volume, s_label)\n",
    "\n",
    "    print('Viewing Stitched Images.....')\n",
    "    volume_3_view_viewer(get_volume_data(volume))\n",
    "    volume_3_view_viewer(get_volume_data(f_volume))\n",
    "    volume_3_view_viewer(get_volume_data(w_volume))\n",
    "    volume_3_view_viewer(get_volume_data(in_volume))\n",
    "    volume_3_view_viewer(get_volume_data(s_label))\n",
    "\n",
    "    print('Saving Processed & Stitched Image.....')\n",
    "    save_volume(volume, f'{processed_dir}/volume/{vol}')\n",
    "    save_volume(f_volume, f'{processed_dir}/volume_f/{vol}')\n",
    "    save_volume(w_volume, f'{processed_dir}/volume_w/{vol}')\n",
    "    save_volume(in_volume, f'{processed_dir}/volume_in/{vol}')\n",
    "    save_volume(s_label, f'{processed_dir}/label/{vol}')\n",
    "    print('FINISHED.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

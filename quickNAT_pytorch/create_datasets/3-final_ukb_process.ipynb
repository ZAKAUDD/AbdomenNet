{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dataset in global_vars.py to UKB.\n",
    "from global_vars import *\n",
    "from commons import *\n",
    "\n",
    "import glob \n",
    "import os\n",
    "\n",
    "one_time_n4_optimization = True\n",
    "vol_to_check_list = None #['1942395_20201_2_0'] #['']\n",
    "exclude = ['1004985_20201_2_0']\n",
    "# 1018320_20201_2_0, 988, test:no-gallbladder=1108214_20201_2_0\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ukb_file_paths(load_from_txt_file=True):\n",
    "    volumes_to_use = []\n",
    "    if load_from_txt_file:\n",
    "        with open(volume_txt_file) as file_handle:\n",
    "                volumes_to_use = file_handle.read().splitlines()\n",
    "    else:\n",
    "        volumes_to_use = [name for name in os.listdir(data_dir)[:2]]\n",
    "\n",
    "    file_paths = {}\n",
    "    \n",
    "    for vol in volumes_to_use:\n",
    "        if (vol_to_check_list is not None and vol not in vol_to_check_list) or (vol == \"\") or (vol in exclude):\n",
    "            continue\n",
    "#         if vol != '1002359_20201_2_0':\n",
    "#             continue\n",
    "            \n",
    "        opp_paths = glob.glob(f'{data_dir}/{vol}/**opp**_[17s, 17sa,17sb]**.nii.gz')\n",
    "        in_paths = glob.glob(f'{data_dir}/{vol}/**in**_[17s,17sa,17sb]**.nii.gz')\n",
    "        f_paths = glob.glob(f'{data_dir}/{vol}/**F**_[17s, 17sa,17sb]**.nii.gz')\n",
    "        w_paths = glob.glob(f'{data_dir}/{vol}/**W**_[17s, 17sa,17sb]**.nii.gz')\n",
    "        \n",
    "        labelmap_paths = glob.glob(f'{label_dir}/{vol}/**')\n",
    "        \n",
    "        vol_madals_paths = dict(\n",
    "        OPP=opp_paths,\n",
    "        IN=in_paths,\n",
    "        F=f_paths,\n",
    "        W=w_paths\n",
    "        )\n",
    "        file_paths[str(vol)]=dict(\n",
    "            VOLUME_PATHS=vol_madals_paths,\n",
    "            LABEL_PATHS=labelmap_paths,\n",
    "        )\n",
    "    return file_paths\n",
    "\n",
    "file_paths = load_ukb_file_paths(False)\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual RESCALING.\n",
    "n4_dict = {}\n",
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4 processing part-1 started with {vol}...')\n",
    "    n4_dict[vol] = []\n",
    "    vol_parts = [[file, read_ras(file)] for file in file_paths[vol]['VOLUME_PATHS']['IN']]\n",
    "    for orig_file, in_image in vol_parts:\n",
    "        n4_dict[vol].append(rescale(in_image, vol, orig_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITK does ot work due to differences in pixel resolution of IN and corresponding OPP Scan.\n",
    "# Only applying once at the end.\n",
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4-biasfield-correction starting with {vol}...')\n",
    "    for idx, n4_d in enumerate(n4_dict[vol]):\n",
    "        in_file = n4_d['SCALED']\n",
    "        opp_file = file_paths[vol]['VOLUME_PATHS']['OPP'][idx]\n",
    "        new_filename = opp_file.split('/')[-1].split('.')[0]\n",
    "        output_file = f'{n4_corrected_data_dir}/vol/{vol}/{new_filename}_n4_corrected_sitk.nii.gz'\n",
    "        SITK_N4_normalization(in_file, opp_file, output_file)\n",
    "        n4_dict[vol][idx]['OPP_CORRECTED'] = output_file\n",
    "\n",
    "    file_paths[vol]['N4_1'] = n4_dict[vol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STITCHING VOL PARTS HERE\n",
    "for vol in file_paths.keys():\n",
    "    try:\n",
    "        print(f'started with {vol}...')\n",
    "        if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "            continue\n",
    "        create_if_not(f'{n4_corrected_data_dir}/vol/{vol}')\n",
    "        file_paths[vol]['ONE'] = {}\n",
    "        for modality_key in file_paths[vol]['VOLUME_PATHS'].keys():\n",
    "            print(f\"processing {modality_key}\")\n",
    "            orig_modal_key = modality_key\n",
    "            if one_time_n4_optimization:\n",
    "                vol_parts = [read_ras(file) for file in file_paths[vol]['VOLUME_PATHS'][modality_key]]\n",
    "            else:\n",
    "                if modality_key == 'OPP':\n",
    "                    vol_parts = [read_ras(data_dict['OPP_CORRECTED']) for data_dict in file_paths[vol]['N4_1']]\n",
    "                    modality_key = modality_key+'_n4_corrected'\n",
    "                else:\n",
    "                    vol_parts = [read_ras(file) for file in file_paths[vol]['VOLUME_PATHS'][modality_key]]\n",
    "\n",
    "            ras_stitched = multi_vol_stitching(vol_parts, sampling=SAMPLING)\n",
    "            save_volume(ras_stitched, f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched', np.int16)\n",
    "            file_paths[vol]['ONE'][f'{orig_modal_key}'] = f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched.nii.gz'\n",
    "    except Exception as e:\n",
    "        print('ERROR:', e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESCALING INTENSITIES OF STITCHED VOLUME ABOVE 0\n",
    "n4_dict = {}\n",
    "for vol in file_paths.keys():\n",
    "    try:\n",
    "        if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "            continue\n",
    "        print(f'n4 processing part-2 started with {vol}...')\n",
    "        if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "            continue\n",
    "        n4_dict[vol] = {}\n",
    "        in_stitched_file_path, in_stitched_img = file_paths[vol]['ONE']['IN'], read_ras(file_paths[vol]['ONE']['IN'])\n",
    "        n4_dict[vol]['N4_2'] = rescale(in_stitched_img, vol, in_stitched_file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('ERROR:',e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_n4_process = True\n",
    "for vol in file_paths.keys():\n",
    "    try:\n",
    "        if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "            continue\n",
    "        print(f'n4-biasfield-correction starting with {vol}...')\n",
    "        in_file = n4_dict[vol]['N4_2']['SCALED']\n",
    "        opp_file = file_paths[vol]['ONE']['OPP']\n",
    "        if all_n4_process:\n",
    "            w_file = file_paths[vol]['ONE']['W']\n",
    "            w_of = w_file.split('/')[-1].split('.')[0]\n",
    "            w_outputfile = f'{n4_corrected_data_dir}/vol/{vol}/{w_of}_n4_corrected_sitk.nii.gz'\n",
    "            SITK_N4_normalization(in_file, w_file, w_outputfile)\n",
    "            n4_dict[vol]['N4_2']['W_CORRECTED'] = w_outputfile\n",
    "            \n",
    "            f_file = file_paths[vol]['ONE']['F']\n",
    "            f_of = f_file.split('/')[-1].split('.')[0]\n",
    "            f_outputfile = f'{n4_corrected_data_dir}/vol/{vol}/{f_of}_n4_corrected_sitk.nii.gz'\n",
    "            SITK_N4_normalization(in_file, f_file, f_outputfile)\n",
    "            n4_dict[vol]['N4_2']['F_CORRECTED'] = f_outputfile\n",
    "            \n",
    "            inin_file = file_paths[vol]['ONE']['IN']\n",
    "            in_of = inin_file.split('/')[-1].split('.')[0]\n",
    "            in_outputfile = f'{n4_corrected_data_dir}/vol/{vol}/{in_of}_n4_corrected_sitk.nii.gz'\n",
    "            SITK_N4_normalization(in_file, inin_file, in_outputfile)\n",
    "            n4_dict[vol]['N4_2']['IN_CORRECTED'] = in_outputfile\n",
    "            \n",
    "        new_filename = opp_file.split('/')[-1].split('.')[0]\n",
    "        output_file = f'{n4_corrected_data_dir}/vol/{vol}/{new_filename}_n4_corrected_sitk.nii.gz'\n",
    "        SITK_N4_normalization(in_file, opp_file, output_file)\n",
    "        n4_dict[vol]['N4_2']['OPP_CORRECTED'] = output_file\n",
    "        file_paths[vol]['N4_2'] = n4_dict[vol]['N4_2']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('ERROR:',e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ukb_vol_label_fix(vol, label, use_alternate_approach=False):\n",
    "    world_shape = np.max(np.array([list(vol.shape), list(label.shape)]), axis=0)\n",
    "    final_label = np.zeros(tuple(world_shape))\n",
    "    \n",
    "    label_affine = label.affinevolume = hist_match(volume)\n",
    "    vol_affine = vol.affine\n",
    "    target_affine = vol_affine\n",
    "    target_header = vol.header\n",
    "\n",
    "    sx,sy,sz,ex,ey,ez = np.abs(get_points(label, vol))\n",
    "    labelmap = label.get_fdata()\n",
    "    \n",
    "    if not use_alternate_approach:\n",
    "        final_label[0:sx+ex, 0:sy+ey, sz:ez] = labelmap\n",
    "    else:\n",
    "        final_label[0:sx+ex, 0:sy+ey, sz-20:ez-20] = labelmap\n",
    "\n",
    "    final_label = np.flip(final_label, axis=0)\n",
    "    final_label = np.flip(final_label, axis=1)\n",
    "    \n",
    "    final_label_img = nb.Nifti1Image(final_label, target_affine, target_header)\n",
    "    \n",
    "    return vol, final_label_img\n",
    "\n",
    "def ukb_label_parts(label_parts, reference_labelmap=None):\n",
    "    stitched_label = None\n",
    "    mode = 'constant'\n",
    "    order = 0\n",
    "    if reference_labelmap is None:\n",
    "        label_shape = np.max([img.shape for img, _, _ in label_parts], axis=0)\n",
    "        reference_labelmap = [img for img, _, _ in label_parts if list(img.shape) == list(label_shape)][0]\n",
    "    else:\n",
    "        label_shape = reference_labelmap.shape\n",
    "\n",
    "    stitched_label = np.zeros(label_shape)\n",
    "    for labelmap_img, lidx, lname in label_parts:\n",
    "        print(lidx, lname)\n",
    "        labelmap_img = makeit_3d(labelmap_img)\n",
    "        labelmap_img = resample_from_to(labelmap_img, [label_shape, reference_labelmap.affine], order=order, mode=mode, cval=0)\n",
    "        \n",
    "        sx,sy,sz,ex,ey,ez = np.abs(get_points(labelmap_img, reference_labelmap))\n",
    "        \n",
    "        labelmap = labelmap_img.get_fdata()\n",
    "        labelmap = np.multiply(lidx, labelmap)\n",
    "        stitched_label[0:ex+sx, 0:ey+sy, 0:ez+sz] += labelmap\n",
    "        \n",
    "        print(\"###############################################################################################\") \n",
    "        \n",
    "    labelmap = np.round(stitched_label)\n",
    "    stitched_labeled_img = nb.Nifti1Image(labelmap, reference_labelmap.affine, reference_labelmap.header)\n",
    "    \n",
    "    return stitched_labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STARTING NAKO LABEL-MAPS.\")\n",
    "print('Reading Label Maps.....')\n",
    "for vol in file_paths.keys():\n",
    "    print(vol)\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    later = None\n",
    "    print(file_paths[vol]['LABEL_PATHS'])\n",
    "    if len(file_paths[vol]['LABEL_PATHS']) == 0:\n",
    "        print(f\"#################### ALERT:: NO LABELPATHS IN THE DICTIONARY FOR {vol} #########################\")\n",
    "        continue\n",
    "        \n",
    "    volume = nb.load(file_paths[vol]['N4_2']['OPP_CORRECTED'])\n",
    "    f_volume = nb.load(file_paths[vol]['N4_2']['F_CORRECTED'])\n",
    "    w_volume = nb.load(file_paths[vol]['N4_2']['W_CORRECTED'])\n",
    "    in_volume = nb.load(file_paths[vol]['N4_2']['IN_CORRECTED'])\n",
    "#     volume = nb.load(file_paths[vol]['ONE']['OPP'])\n",
    "    img_ras_list = []\n",
    "    later = []\n",
    "    for label_file_to_read in file_paths[vol]['LABEL_PATHS']:\n",
    "        img_ras, lidx, labelname = read_ras(label_file_to_read, is_label=True)\n",
    "        if labelname is None or img_ras is None:\n",
    "            continue\n",
    "        img_ras = makeit_3d(img_ras)\n",
    "        print('After 3d confirmed:', img_ras.shape)\n",
    "        mode='nearest'\n",
    "        if SAMPLING:\n",
    "            img_ras = resample_to_output(img_ras, TARGET_RESOLUTION, order=0, mode=mode, cval=0.0)\n",
    "        \n",
    "        if labelname in ['SPLEEN', 'PANCREAS']:\n",
    "            later.append([img_ras, lidx+LABEL_EXTENSION_FOR_OVERLAP_REMOVAL, labelname])\n",
    "        else:\n",
    "            img_ras_list.append([img_ras, lidx+LABEL_EXTENSION_FOR_OVERLAP_REMOVAL, labelname])\n",
    "\n",
    "    img_ras_list.extend(later)\n",
    "        \n",
    "    s_label = ukb_label_parts(img_ras_list)\n",
    "    s_label = drop_overlapped_pixels(s_label, np.array(img_ras_list)[:, 1])\n",
    "    \n",
    "    if vol == '1004985_20201_2_0':\n",
    "        volume, s_label = ukb_vol_label_fix(volume, s_label, True)\n",
    "    else:\n",
    "        volume, s_label = ukb_vol_label_fix(volume, s_label)\n",
    "    \n",
    "    print('Viewing Stitched Images.....')\n",
    "    volume_3_view_viewer(get_volume_data(volume))\n",
    "    volume_3_view_viewer(get_volume_data(f_volume))\n",
    "    volume_3_view_viewer(get_volume_data(w_volume))\n",
    "    volume_3_view_viewer(get_volume_data(in_volume))\n",
    "    volume_3_view_viewer(get_volume_data(s_label))\n",
    "\n",
    "    print('Saving Processed & Stitched Image.....')\n",
    "    save_volume(volume, f'{processed_dir}/volume/{vol}')\n",
    "    save_volume(f_volume, f'{processed_dir}/volume_f/{vol}')\n",
    "    save_volume(w_volume, f'{processed_dir}/volume_w/{vol}')\n",
    "    save_volume(in_volume, f'{processed_dir}/volume_in/{vol}')\n",
    "    save_volume(s_label, f'{processed_dir}/label/{vol}')\n",
    "    print('FINISHED.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ras = nb.load('/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/processed/volume/1002359_20201_2_0.nii.gz')\n",
    "# print(TARGET_RESOLUTION)\n",
    "# img_ras = resample_to_output(img_ras, [3,3,5], order=3, mode='constant', cval=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume_3_view_viewer(get_volume_data(img_ras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_volume(img_ras, f'{processed_dir}/volume_sampled/{vol}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37419"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/**/**.nii.gz')\n",
    "len(files)\n",
    "# import os\n",
    "# for f in files:\n",
    "#     os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1015918_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1022975_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1025142_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026160_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026714_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026955_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027038_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027598_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027672_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1028818_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz',\n",
       " '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1029414_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "up_files = [f for f in files if os.path.getsize(f) > 18000000]\n",
    "up_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1015918_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1015918_20201_2_0\n",
      "Compressed file ended before the end-of-stream marker was reached\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1022975_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1022975_20201_2_0\n",
      "Error -3 while decompressing data: invalid code lengths set\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1025142_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1025142_20201_2_0\n",
      "Compressed file ended before the end-of-stream marker was reached\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026160_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026160_20201_2_0\n",
      "Error -3 while decompressing data: invalid block type\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026714_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026714_20201_2_0\n",
      "Error -3 while decompressing data: invalid stored block lengths\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026955_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1026955_20201_2_0\n",
      "Error -3 while decompressing data: invalid block type\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027038_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027038_20201_2_0\n",
      "Compressed file ended before the end-of-stream marker was reached\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027598_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027598_20201_2_0\n",
      "Compressed file ended before the end-of-stream marker was reached\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027672_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1027672_20201_2_0\n",
      "Compressed file ended before the end-of-stream marker was reached\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1028818_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1028818_20201_2_0\n",
      "Error -3 while decompressing data: invalid block type\n",
      "/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1029414_20201_2_0/OPP_ras_stitched_n4_corrected_sitk.nii.gz\n",
      "saving directory: /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/UKB/n4_corrected_2/vol/1029414_20201_2_0\n",
      "Compressed file ended before the end-of-stream marker was reached\n"
     ]
    }
   ],
   "source": [
    "for f in up_files:\n",
    "    try:\n",
    "        print(f)\n",
    "        img = nb.load(f)\n",
    "        fi = f.split('.')[0]\n",
    "        save_volume(img, fi, to_dtype=np.int16)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:remotenv]",
   "language": "python",
   "name": "conda-env-remotenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

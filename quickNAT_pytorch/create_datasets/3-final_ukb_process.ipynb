{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dataset in global_vars.py to UKB.\n",
    "from global_vars import *\n",
    "from commons import *\n",
    "\n",
    "import glob \n",
    "import os\n",
    "\n",
    "one_time_n4_optimization = True\n",
    "vol_to_check_list = None #['1942395_20201_2_0'] #['']\n",
    "exclude = ['1004985_20201_2_0']\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ukb_file_paths(load_from_txt_file=True):\n",
    "    volumes_to_use = []\n",
    "    if load_from_txt_file:\n",
    "        with open(volume_txt_file) as file_handle:\n",
    "                volumes_to_use = file_handle.read().splitlines()\n",
    "    else:\n",
    "        volumes_to_use = [name for name in os.listdir(data_dir)]\n",
    "\n",
    "    file_paths = {}\n",
    "    \n",
    "    for vol in volumes_to_use:\n",
    "        if (vol_to_check_list is not None and vol not in vol_to_check_list) or (vol == \"\") or (vol in exclude):\n",
    "            continue\n",
    "            \n",
    "        opp_paths = glob.glob(f'{data_dir}/{vol}/**opp**_[17s, 17sa,17sb]**.nii.gz')\n",
    "        in_paths = glob.glob(f'{data_dir}/{vol}/**in**_[17s,17sa,17sb]**.nii.gz')\n",
    "        f_paths = glob.glob(f'{data_dir}/{vol}/**F**_[17s, 17sa,17sb]**.nii.gz')\n",
    "        w_paths = glob.glob(f'{data_dir}/{vol}/**W**_[17s, 17sa,17sb]**.nii.gz')\n",
    "        \n",
    "        labelmap_paths = glob.glob(f'{label_dir}/{vol}/**')\n",
    "        \n",
    "        vol_madals_paths = dict(\n",
    "        OPP=opp_paths,\n",
    "        IN=in_paths,\n",
    "        F=f_paths,\n",
    "        W=w_paths\n",
    "        )\n",
    "        file_paths[str(vol)]=dict(\n",
    "            VOLUME_PATHS=vol_madals_paths,\n",
    "            LABEL_PATHS=labelmap_paths,\n",
    "        )\n",
    "    return file_paths\n",
    "\n",
    "file_paths = load_ukb_file_paths()\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual RESCALING.\n",
    "n4_dict = {}\n",
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4 processing part-1 started with {vol}...')\n",
    "    n4_dict[vol] = []\n",
    "    vol_parts = [[file, read_ras(file)] for file in file_paths[vol]['VOLUME_PATHS']['IN']]\n",
    "    for orig_file, in_image in vol_parts:\n",
    "        n4_dict[vol].append(rescale(in_image, vol, orig_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EXECUTE 'sudo sh ./n4-anne.sh' from command line for n4 bais field generation of all in imgs.\n",
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'applying n4 bias field on opp scans of {vol}...')\n",
    "    vol_parts = [[read_ras(opp_file), read_ras(n4_counterpart['IN_BIAS']), opp_file] for opp_file, n4_counterpart in zip(file_paths[vol]['VOLUME_PATHS']['OPP'],n4_dict[vol])]\n",
    "    idx = 0\n",
    "    file_paths[vol]['N4_1'] = []\n",
    "    for opp_img, bias_field_img, opp_file in vol_parts:\n",
    "        file_paths[vol]['N4_1'].append(apply_bias_field(opp_img, bias_field_img, opp_file, n4_dict[vol][idx], vol))\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STITCHING VOL PARTS HERE\n",
    "for vol in file_paths.keys():\n",
    "    print(f'started with {vol}...')\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    create_if_not(f'{n4_corrected_data_dir}/vol/{vol}')\n",
    "    file_paths[vol]['ONE'] = {}\n",
    "    for modality_key in file_paths[vol]['VOLUME_PATHS'].keys():\n",
    "        print(f\"processing {modality_key}\")\n",
    "        orig_modal_key = modality_key\n",
    "        if one_time_n4_optimization:\n",
    "            vol_parts = [read_ras(file) for file in file_paths[vol]['VOLUME_PATHS'][modality_key]]\n",
    "        else:\n",
    "            if modality_key == 'OPP':\n",
    "                vol_parts = [read_ras(data_dict['OPP_CORRECTED']) for data_dict in file_paths[vol]['N4_1']]\n",
    "                modality_key = modality_key+'_n4_corrected'\n",
    "            else:\n",
    "                vol_parts = [read_ras(file) for file in file_paths[vol]['VOLUME_PATHS'][modality_key]]\n",
    "\n",
    "        ras_stitched = multi_vol_stitching(vol_parts)\n",
    "        save_volume(ras_stitched, f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched')\n",
    "        file_paths[vol]['ONE'][f'{orig_modal_key}'] = f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESCALING INTENSITIES OF STITCHED VOLUME ABOVE 0\n",
    "n4_dict = {}\n",
    "for vol in file_paths.keys():\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4 processing part-2 started with {vol}...')\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    n4_dict[vol] = {}\n",
    "    in_stitched_file_path, in_stitched_img = file_paths[vol]['ONE']['IN'], read_ras(file_paths[vol]['ONE']['IN'])\n",
    "    n4_dict[vol]['N4_2'] = rescale(in_stitched_img, vol, in_stitched_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EXECUTE 'sudo sh ./n4-anne-2.sh' from command line for n4 bais field generation of all in imgs.\n",
    "for vol in file_paths.keys():\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'applying n4 bias field on stitched opp scans of {vol}...')\n",
    "    opp_file = file_paths[vol]['ONE']['OPP']\n",
    "    n4_counterpart = n4_dict[vol]['N4_2']\n",
    "    print(opp_file, n4_counterpart['IN_BIAS'])\n",
    "    opp_img = read_ras(opp_file)\n",
    "    bias_field_img = read_ras(n4_counterpart['IN_BIAS'])\n",
    "\n",
    "    file_paths[vol]['N4_2'] = apply_bias_field(opp_img, bias_field_img, opp_file, n4_dict[vol]['N4_2'], vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ukb_vol_label_fix(vol, label, use_alternate_approach=False):\n",
    "    world_shape = np.max(np.array([list(vol.shape), list(label.shape)]), axis=0)\n",
    "    final_label = np.zeros(tuple(world_shape))\n",
    "    \n",
    "    label_affine = label.affinevolume = hist_match(volume)\n",
    "    vol_affine = vol.affine\n",
    "    target_affine = vol_affine\n",
    "    target_header = vol.header\n",
    "\n",
    "    sx,sy,sz,ex,ey,ez = np.abs(get_points(label, vol))\n",
    "    labelmap = label.get_fdata()\n",
    "    \n",
    "    if not use_alternate_approach:\n",
    "        final_label[0:sx+ex, 0:sy+ey, sz:ez] = labelmap\n",
    "    else:\n",
    "        final_label[0:sx+ex, 0:sy+ey, sz-20:ez-20] = labelmap\n",
    "\n",
    "    final_label = np.flip(final_label, axis=0)\n",
    "    final_label = np.flip(final_label, axis=1)\n",
    "    \n",
    "    final_label_img = nb.Nifti1Image(final_label, target_affine, target_header)\n",
    "    \n",
    "    return vol, final_label_img\n",
    "\n",
    "def ukb_label_parts(label_parts, reference_labelmap=None):\n",
    "    stitched_label = None\n",
    "    mode = 'constant'\n",
    "    order = 0\n",
    "    if reference_labelmap is None:\n",
    "        label_shape = np.max([img.shape for img, _, _ in label_parts], axis=0)\n",
    "        reference_labelmap = [img for img, _, _ in label_parts if list(img.shape) == list(label_shape)][0]\n",
    "    else:\n",
    "        label_shape = reference_labelmap.shape\n",
    "\n",
    "    stitched_label = np.zeros(label_shape)\n",
    "    for labelmap_img, lidx, lname in label_parts:\n",
    "        print(lidx, lname)\n",
    "        labelmap_img = makeit_3d(labelmap_img)\n",
    "        labelmap_img = resample_from_to(labelmap_img, [label_shape, reference_labelmap.affine], order=order, mode=mode, cval=0)\n",
    "        \n",
    "        sx,sy,sz,ex,ey,ez = np.abs(get_points(labelmap_img, reference_labelmap))\n",
    "        \n",
    "        labelmap = labelmap_img.get_fdata()\n",
    "        labelmap = np.multiply(lidx, labelmap)\n",
    "        stitched_label[0:ex+sx, 0:ey+sy, 0:ez+sz] += labelmap\n",
    "        \n",
    "        print(\"###############################################################################################\") \n",
    "        \n",
    "    labelmap = np.round(stitched_label)\n",
    "    stitched_labeled_img = nb.Nifti1Image(labelmap, reference_labelmap.affine, reference_labelmap.header)\n",
    "    \n",
    "    return stitched_labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STARTING NAKO LABEL-MAPS.\")\n",
    "print('Reading Label Maps.....')\n",
    "for vol in file_paths.keys():\n",
    "    print(vol)\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    later = None\n",
    "    print(file_paths[vol]['LABEL_PATHS'])\n",
    "    if len(file_paths[vol]['LABEL_PATHS']) == 0:\n",
    "        print(f\"#################### ALERT:: NO LABELPATHS IN THE DICTIONARY FOR {vol} #########################\")\n",
    "        continue\n",
    "        \n",
    "    volume = nb.load(file_paths[vol]['N4_2']['OPP_CORRECTED'])\n",
    "#     volume = nb.load(file_paths[vol]['ONE']['OPP'])\n",
    "    img_ras_list = []\n",
    "    later = []\n",
    "    for label_file_to_read in file_paths[vol]['LABEL_PATHS']:\n",
    "        img_ras, lidx, labelname = read_ras(label_file_to_read, is_label=True)\n",
    "        if labelname is None or img_ras is None:\n",
    "            continue\n",
    "        img_ras = makeit_3d(img_ras)\n",
    "        print('After 3d confirmed:', img_ras.shape)\n",
    "        mode='constant'\n",
    "        img_ras = resample_to_output(img_ras, TARGET_RESOLUTION, order=0, mode=mode, cval=0.0)\n",
    "        \n",
    "        if labelname in ['SPLEEN', 'PANCREAS']:\n",
    "            later.append([img_ras, lidx+LABEL_EXTENSION_FOR_OVERLAP_REMOVAL, labelname])\n",
    "        else:\n",
    "            img_ras_list.append([img_ras, lidx+LABEL_EXTENSION_FOR_OVERLAP_REMOVAL, labelname])\n",
    "\n",
    "    img_ras_list.extend(later)\n",
    "        \n",
    "    s_label = ukb_label_parts(img_ras_list)\n",
    "    s_label = drop_overlapped_pixels(s_label, np.array(img_ras_list)[:, 1])\n",
    "    \n",
    "    if vol == '1004985_20201_2_0':\n",
    "        volume, s_label = ukb_vol_label_fix(volume, s_label, True)\n",
    "    else:\n",
    "        volume, s_label = ukb_vol_label_fix(volume, s_label)\n",
    "\n",
    "    volume = hist_match(volume)\n",
    "    \n",
    "    print('Viewing Stitched Images.....')\n",
    "    volume_3_view_viewer(get_volume_data(volume))\n",
    "    volume_3_view_viewer(get_volume_data(s_label))\n",
    "\n",
    "    print('Saving Processed & Stitched Image.....')\n",
    "    save_volume(volume, f'{processed_dir}/volume/{vol}')\n",
    "    save_volume(s_label, f'{processed_dir}/label/{vol}')\n",
    "    print('FINISHED.')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

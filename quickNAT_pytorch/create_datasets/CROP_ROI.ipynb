{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from global_vars import *\n",
    "from commons import *\n",
    "                                                                                                                                                                                                                                                                                                                                                            \n",
    "import pickle as p\n",
    "import glob \n",
    "import json\n",
    "import subprocess\n",
    "import getpass\n",
    "import os\n",
    "from nibabel.orientations import axcodes2ornt, ornt_transform, inv_ornt_aff, flip_axis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# is_cords_finalized = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'datasets/{dataset}/volumes.txt') as file_handle:\n",
    "    volumes_to_use = file_handle.read().splitlines()\n",
    "print(volumes_to_use)\n",
    "\n",
    "# for idx, i in enumerate(glob.glob(f'{data_dir}/**')):\n",
    "#     vol = i.split('/')[-1]\n",
    "#     if vol not in volumes_to_use and idx < 1000:\n",
    "#         print(vol)\n",
    "    \n",
    "#     if idx > 1000:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_labels(paths):\n",
    "    affine = None\n",
    "    data = np.zeros((256,256,400))\n",
    "    for idx, path in enumerate(paths):\n",
    "        print(path)\n",
    "        img = nb.load(path)\n",
    "        if affine is None:\n",
    "            affine = img.affine\n",
    "        img_data= img.get_fdata()\n",
    "        x,y,z = img.shape\n",
    "        data[:x, :y, :z] += img_data\n",
    "        \n",
    "    empty_header = nibabel.Nifti1Header()\n",
    "    all_label_img = nb.Nifti1Image(data, affine, empty_header)\n",
    "    return all_label_img\n",
    "\n",
    "def resize(img, shape=(256, 256, 400), is_label=False):\n",
    "    if is_label:\n",
    "        order = 0\n",
    "    else:\n",
    "        order = 3\n",
    "    mode='constant'\n",
    "    print(img.shape)\n",
    "    img = resample_from_to(img, [shape, img.affine], order=order, mode=mode, cval=0)\n",
    "    return img\n",
    "\n",
    "def crop(paths, shape, img=None):\n",
    "    s1, e1, s2, e2, s3, e3 = shape\n",
    "    for path in paths:\n",
    "        img = nb.load(path) if img is None else img\n",
    "        img_data= img.get_fdata()\n",
    "        data = img_data[s1:e1, s2:e2, s3:e3]\n",
    "        img = nb.Nifti1Image(data, img.affine, img.header)\n",
    "        save_path = '/'.join(path.split('/')[:-1])\n",
    "        vol_id = path.split('/')[-1].split('.')[0]\n",
    "        save_volume(img, f'{save_path}_cropped/{vol_id}')\n",
    "\n",
    "def remove_black(labelmap):\n",
    "    clean_labels = []\n",
    "    start, end = None, None\n",
    "    start_2, end_2 = None, None\n",
    "    for i, frame in enumerate(labelmap):\n",
    "        unique, counts = np.unique(frame, return_counts=True)\n",
    "        if counts[0] / sum(counts) < .99:\n",
    "            clean_labels.append(frame)\n",
    "            if start is None:\n",
    "                start = i\n",
    "            elif start_2 is None:\n",
    "                start_2 = i\n",
    "            if end is not None:\n",
    "                end_2 = end\n",
    "            end = None\n",
    "        if end is None:\n",
    "            end = i\n",
    "    if end is None:\n",
    "        end = labelmap.shape[0]\n",
    "            \n",
    "    return np.array(clean_labels), start, end, start_2, end_2\n",
    "\n",
    "def remove_black_3channels(data,fat,water,labels):\n",
    "    clean_data,clean_fat,clean_water, clean_labels = [], [],[],[]\n",
    "    for i, frame in enumerate(labels):\n",
    "        unique, counts = np.unique(frame, return_counts=True)\n",
    "        if counts[0] / sum(counts) < .99:\n",
    "            clean_labels.append(frame)\n",
    "            clean_data.append(data[i])\n",
    "            clean_water.append(water[i])\n",
    "            clean_fat.append(fat[i])\n",
    "    return np.array(clean_data), np.array(clean_fat), np.array(clean_water), np.array(clean_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = f'{DEFAULT_OUTPUT_PATH}/KORA/processed'\n",
    "kora_labels = glob.glob(f'{processed_dir}/label/**')\n",
    "kora_volumes = glob.glob(f'{processed_dir}/volume/**')\n",
    "kora_volumes_f = glob.glob(f'{processed_dir}/volume_f/**')\n",
    "kora_volumes_w = glob.glob(f'{processed_dir}/volume_w/**')\n",
    "kora_volumes_in = glob.glob(f'{processed_dir}/volume_in/**')\n",
    "\n",
    "processed_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/processed'\n",
    "nako_labels = glob.glob(f'{processed_dir}/label/100112**')\n",
    "nako_volumes = glob.glob(f'{processed_dir}/volume/100112**')\n",
    "nako_volumes_f = glob.glob(f'{processed_dir}/volume_f/100112**')\n",
    "nako_volumes_w = glob.glob(f'{processed_dir}/volume_w/100112**')\n",
    "nako_volumes_in = glob.glob(f'{processed_dir}/volume_in/100112**')\n",
    "\n",
    "processed_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/n4_corrected_2/vol/**'\n",
    "# ukb_labels = glob.glob(f'{processed_dir}/label/**')\n",
    "ukb_volumes = glob.glob(f'{processed_dir}/OPP_ras_stitched_n4_corrected_sitk.nii.gz')\n",
    "ukb_volumes_f = glob.glob(f'{processed_dir}/F_ras_stitched_n4_corrected_sitk.nii.gz')\n",
    "ukb_volumes_w = glob.glob(f'{processed_dir}/W_ras_stitched_n4_corrected_sitk.nii.gz')\n",
    "ukb_volumes_in = glob.glob(f'{processed_dir}/IN_ras_stitched_n4_corrected_sitk.nii.gz')\n",
    "\n",
    "ukb1_volumes = glob.glob(f'{processed_dir}/OPP_ras_stitched.nii.gz')\n",
    "ukb1_volumes_f = glob.glob(f'{processed_dir}/F_ras_stitched.nii.gz')\n",
    "ukb1_volumes_w = glob.glob(f'{processed_dir}/W_ras_stitched.nii.gz')\n",
    "ukb1_volumes_in = glob.glob(f'{processed_dir}/IN_ras_stitched.nii.gz')\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/processed'\n",
    "# nako_labels = glob.glob(f'{processed_dir}/label/**')\n",
    "# nako_volumes = glob.glob(f'{processed_dir}/volume/**')\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/processed'\n",
    "# ukb_labels = glob.glob(f'{processed_dir}/label/**')\n",
    "# ukb_volumes = glob.glob(f'{processed_dir}/volume/**')\n",
    "\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/KORA/n4_corrected_2'\n",
    "# # kora_labels = glob.glob(f'{processed_dir}/label/**')\n",
    "# kora_volumes = glob.glob(f'{processed_dir}/vol/**/**_sitk.nii.gz')\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/n4_corrected_2'\n",
    "# # nako_labels = glob.glob(f'{processed_dir}/label/**')\n",
    "# nako_volumes = glob.glob(f'{processed_dir}/vol/**/**_sitk.nii.gz')\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/n4_corrected_2'\n",
    "# # ukb_labels = glob.glob(f'{processed_dir}/label/**')\n",
    "# ukb_volumes = glob.glob(f'{processed_dir}/vol/**/**_sitk.nii.gz')\n",
    "\n",
    "# all_labels =  kora_labels+nako_labels+ukb_labels\n",
    "# all_volumes = kora_volumes + nako_volumes + ukb_volumes\n",
    "\n",
    "# all_volumes =  kora_volumes + kora_volumes_f + kora_volumes_w +kora_volumes_in + nako_volumes + nako_volumes_f + nako_volumes_w +nako_volumes_in + ukb_volumes + ukb_volumes_f + ukb_volumes_w +ukb_volumes_in\n",
    "all_ukb = ukb_volumes + ukb_volumes_f + ukb_volumes_w + ukb_volumes_in\n",
    "all_ukb1 = ukb1_volumes + ukb1_volumes_f + ukb1_volumes_w + ukb1_volumes_in\n",
    "\n",
    "all_u = all_ukb+all_ukb1\n",
    "# all_nako = nako_volumes + nako_volumes_f + nako_volumes_w + nako_volumes_in\n",
    "# print(all_volumes, len(all_volumes))\n",
    "# print(kora_volumes, kora_labels)\n",
    "# out of 1534, 1507 volumes got processed, 27 rogue volumes across 3 dataset.\n",
    "# all_nako"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol in all_u:\n",
    "    print(vol)\n",
    "    vol_id = vol.split('/')[-1].split('.')[0]\n",
    "#     vol_id = vol.split('/')[-2]\n",
    "    save_path = '/'.join(vol.split('/')[:-1])\n",
    "    print(vol_id, save_path)\n",
    "    vol_img = nb.load(vol)\n",
    "    resized_img = resize(vol_img)\n",
    "    crop([vol], [16, 208, 0, 174, 3, 115], resized_img)\n",
    "#     save_volume(resized_img, f'{save_path}_resized/{vol_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol in nako_labels:\n",
    "    vol_id = vol.split('/')[-1].split('.')[0]\n",
    "    save_path = '/'.join(vol.split('/')[:-1])\n",
    "    print(vol_id, save_path)\n",
    "    vol_img = nb.load(vol)\n",
    "    resized_img = resize(vol_img, is_label=True)\n",
    "    save_volume(resized_img, f'{save_path}_resized/{vol_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_resized_dir = f'{DEFAULT_OUTPUT_PATH}/KORA/processed'\n",
    "kora_labels = glob.glob(f'{processed_resized_dir}/label_resized/**')\n",
    "kora_volumes = glob.glob(f'{processed_resized_dir}/volume_resized/**')\n",
    "kora_fvolumes = glob.glob(f'{processed_resized_dir}/volume_f_resized/**')\n",
    "kora_wvolumes = glob.glob(f'{processed_resized_dir}/volume_w_resized/**')\n",
    "kora_involumes = glob.glob(f'{processed_resized_dir}/volume_in_resized/**')\n",
    "\n",
    "processed_resized_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/processed'\n",
    "nako_labels = glob.glob(f'{processed_resized_dir}/label_resized/100112**')\n",
    "nako_volumes = glob.glob(f'{processed_resized_dir}/volume_resized/100112**')\n",
    "nako_fvolumes = glob.glob(f'{processed_resized_dir}/volume_f_resized/100112**')\n",
    "nako_wvolumes = glob.glob(f'{processed_resized_dir}/volume_w_resized/100112**')\n",
    "nako_involumes = glob.glob(f'{processed_resized_dir}/volume_in_resized/100112**')\n",
    "\n",
    "processed_resized_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/processed/unsampled'\n",
    "ukb_labels = glob.glob(f'{processed_resized_dir}/label_resized/**')\n",
    "ukb_volumes = glob.glob(f'{processed_resized_dir}/volume_resized/**')\n",
    "ukb_fvolumes = glob.glob(f'{processed_resized_dir}/volume_f_resized/**')\n",
    "ukb_wvolumes = glob.glob(f'{processed_resized_dir}/volume_w_resized/**')\n",
    "ukb_involumes = glob.glob(f'{processed_resized_dir}/volume_in_resized/**')\n",
    "# processed_resized_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/processed_resized'\n",
    "# nako_labels = glob.glob(f'{processed_resized_dir}/label/**')\n",
    "# nako_volumes = glob.glob(f'{processed_resized_dir}/volume/**')\n",
    "# processed_resized_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/processed_resized'\n",
    "# ukb_labels = glob.glob(f'{processed_resized_dir}/label/**')\n",
    "# ukb_volumes = glob.glob(f'{processed_resized_dir}/volume/**')\n",
    "\n",
    "# processed_resized_dir = f'{DEFAULT_OUTPUT_PATH}/KORA/n4_corrected_2/vol_resized'\n",
    "# # kora_labels = glob.glob(f'{processed_resized_dir}/label/**')\n",
    "# kora_volumes = glob.glob(f'{processed_resized_dir}/volume/**')\n",
    "# processed_resized_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/n4_corrected_2/vol_resized'\n",
    "# # nako_labels = glob.glob(f'{processed_resized_dir}/label/**')\n",
    "# nako_volumes = glob.glob(f'{processed_resized_dir}/volume/**')\n",
    "# processed_resized_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/n4_corrected_2/vol_resized'\n",
    "# # ukb_labels = glob.glob(f'{processed_resized_dir}/label/**')\n",
    "# ukb_volumes = glob.glob(f'{processed_resized_dir}/volume/**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kora_fvolumes\n",
    "# nb.load(kora_fvolumes[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kls = add_all_labels(kora_labels)\n",
    "# volume_3_view_viewer(get_volume_data(kls))\n",
    "# save_volume(kls, f'all_labels_merged/all_kora_labels')\n",
    "\n",
    "# kls = add_all_labels(nako_labels)\n",
    "# volume_3_view_viewer(get_volume_data(kls))\n",
    "# save_volume(kls, f'all_labels_merged/all_nako_labels')\n",
    "\n",
    "# kls = add_all_labels(ukb_labels)\n",
    "# volume_3_view_viewer(get_volume_data(kls))\n",
    "# save_volume(kls, f'all_labels_merged/all_ukb_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = nb.load(f'all_labels_merged/all_kora_labels.nii.gz')\n",
    "# img_data = img.get_fdata()\n",
    "# img_d1, s1,e1, s12, e12 = remove_black(img_data)\n",
    "# img_data1 = np.moveaxis(img_data, 1, 0)\n",
    "# img_d2, s2,e2, s22, e22 = remove_black(img_data1)\n",
    "# img_data2 = np.moveaxis(img_data, 2, 0)\n",
    "# img_d3,s3,e3, s32, e32 = remove_black(img_data2)\n",
    "# # img_data = np.moveaxis(img_data, axis=0)\n",
    "\n",
    "# print('kora', img_d1.shape, img_d2.shape, img_d3.shape, s1,e1,s2,e2,s3,e3,'---', s12,e12,s22,e22,s32,e32)\n",
    "\n",
    "# img = nb.load(f'all_labels_merged/all_nako_labels.nii.gz')\n",
    "# img_data = img.get_fdata()\n",
    "# img_d1,s1,e1, s12, e12 = remove_black(img_data)\n",
    "# img_data1 = np.moveaxis(img_data, 1, 0)\n",
    "# img_d2,s2,e2, s22, e22 = remove_black(img_data1)\n",
    "# img_data2 = np.moveaxis(img_data, 2, 0)\n",
    "# img_d3,s3,e3, s32, e32 = remove_black(img_data2)\n",
    "# # img_data = np.moveaxis(img_data, axis=0)\n",
    "\n",
    "# print('nako', img_d1.shape, img_d2.shape, img_d3.shape, s1,e1,s2,e2,s3,e3,'---', s12,e12,s22,e22,s32,e32)\n",
    "\n",
    "# img = nb.load(f'all_labels_merged/all_ukb_labels.nii.gz')\n",
    "# img_data = img.get_fdata()\n",
    "# img_d1,s1,e1, s12, e12 = remove_black(img_data)\n",
    "# img_data1 = np.moveaxis(img_data, 1, 0)\n",
    "# img_d2,s2,e2, s22, e22 = remove_black(img_data1)\n",
    "# img_data2 = np.moveaxis(img_data, 2, 0)\n",
    "# img_d3,s3,e3, s32, e32 = remove_black(img_data2)\n",
    "# # img_data = np.moveaxis(img_data, axis=0)\n",
    "\n",
    "# print('ukb', img_d1.shape, img_d2.shape, img_d3.shape, s1,e1, s2,e2, s3,e3,'---', s12,e12,s22,e22,s32,e32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KORA = 158,100,91   ---  49, 206, 23, 122, 84, 176  --> 40, 210, 5, 145, 80, 180 == 170, 140, 100  == 176, 144, 112/96  (Multiples of 16)\n",
    "#                                                       \"40, 215, 5, 175, 70, 180\" == \"175, 170, 110\" ==  '192 176 112'== 32, 224, 2, 178, 69, 181\n",
    "# NAKO = 158,104,76    --- 44, 201, 40, 143, 169, 244  --> 41, 201, 23, 143, 169, 244 == 160, 120, 75 == 160, 128, 84 =AFTER FAT TALL MATCH= \n",
    "#                                                       31, 201, 23, 143, 160, 265 == \"170, 120, 105\" == '192 176 112' == 20, 212, 0, 176, 157, 269\n",
    "# UKB= 163, 117, 97    --- 47, 209, 42, 158, 80, 176  --> 35, 215, 25, 170, 215, 315 == 180,145, 100 == 176/192, 144/160, 112 =AFTER FAT TALL[Missing] MATCH= \n",
    "#            (Evaluated on 6 merged UKB scans. BH+NOBH) 35, 215, 25, 170, 210, 315 == \"180, 145, 105\" == '192 176 112' == 29, 221, 10, 186, 72, 184  (for BH Merge only)\n",
    " \n",
    "# KORA sample vol size = 250, 188, 370\n",
    "# NAKO sample vol size = 226,184,316\n",
    "# UKB sample vol size = 246, 137, 239\n",
    "# sample target shape = 256, 256,400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(kora_volumes, [32, 224, 2, 178, 69, 181])\n",
    "crop(kora_fvolumes, [32, 224, 2, 178, 69, 181])\n",
    "crop(kora_wvolumes, [32, 224, 2, 178, 69, 181])\n",
    "crop(kora_involumes, [32, 224, 2, 178, 69, 181])\n",
    "\n",
    "# crop(kora_volumes, [0, 256, 0, 192, 61, 189])\n",
    "# crop(kora_fvolumes, [0, 256, 0, 192, 61, 189])\n",
    "# crop(kora_wvolumes, [0, 256, 0, 192, 61, 189])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(kora_labels, [32, 224, 2, 178, 69, 181])\n",
    "# crop(kora_labels, [0, 256, 0, 192, 61, 189])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nako_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(nako_volumes, [20, 212, 0, 176, 157, 269])\n",
    "crop(nako_fvolumes, [20, 212, 0, 176, 157, 269])\n",
    "crop(nako_wvolumes, [20, 212, 0, 176, 157, 269])\n",
    "crop(nako_involumes, [20, 212, 0, 176, 157, 269])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(nako_labels, [20, 212, 0, 176, 157, 269])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ukb = ukb_volumes + ukb_volumes_f + ukb_volumes_w + ukb_volumes_in\n",
    "# crop(ukb_volumes, [29, 221, 10, 186, 72, 184])\n",
    "# crop(ukb_fvolumes, [29, 221, 10, 186, 72, 184])\n",
    "# crop(ukb_wvolumes, [29, 221, 10, 186, 72, 184])\n",
    "# crop(ukb_involumes, [29, 221, 10, 186, 72, 184])\n",
    "# 224, 174, 118    192 176 112\n",
    "crop(ukb_volumes, [16, 208, 0, 174, 3, 115])\n",
    "crop(ukb_volumes_f, [16, 208, 0, 174, 3, 115])\n",
    "crop(ukb_volumes_w, [16, 208, 0, 174, 3, 115])\n",
    "crop(ukb_volumes_in, [16, 208, 0, 174, 3, 115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(ukb_labels, [16, 208, 0, 174, 3, 115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = f'{DEFAULT_OUTPUT_PATH}/KORA/processed'\n",
    "kora_labels_c = sorted(glob.glob(f'{processed_dir}/label_resized_cropped/**'))\n",
    "kora_volumes_c = sorted(glob.glob(f'{processed_dir}/volume_resized_cropped/**'))\n",
    "kora_volumes_c_f = sorted(glob.glob(f'{processed_dir}/volume_f_resized_cropped/**'))\n",
    "kora_volumes_c_w = sorted(glob.glob(f'{processed_dir}/volume_w_resized_cropped/**'))\n",
    "kora_volumes_c_in = sorted(glob.glob(f'{processed_dir}/volume_in_resized_cropped/**'))\n",
    "\n",
    "processed_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/processed'\n",
    "nako_labels_c = sorted(glob.glob(f'{processed_dir}/label_resized_cropped/100112**'))\n",
    "nako_volumes_c = sorted(glob.glob(f'{processed_dir}/volume_resized_cropped/100112**'))\n",
    "nako_volumes_c_f = sorted(glob.glob(f'{processed_dir}/volume_f_resized_cropped/100112**'))\n",
    "nako_volumes_c_w = sorted(glob.glob(f'{processed_dir}/volume_w_resized_cropped/100112**'))\n",
    "nako_volumes_c_in = sorted(glob.glob(f'{processed_dir}/volume_in_resized_cropped/100112**'))\n",
    "\n",
    "processed_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/processed'\n",
    "ukb_labels_c = sorted(glob.glob(f'{processed_dir}/label_resized_cropped/**'))\n",
    "ukb_volumes_c = sorted(glob.glob(f'{processed_dir}/volume_resized_cropped/**'))\n",
    "ukb_volumes_c_f = sorted(glob.glob(f'{processed_dir}/volume_f_resized_cropped/**'))\n",
    "ukb_volumes_c_w = sorted(glob.glob(f'{processed_dir}/volume_w_resized_cropped/**'))\n",
    "ukb_volumes_c_in = sorted(glob.glob(f'{processed_dir}/volume_in_resized_cropped/**'))\n",
    "\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/processed_resized'\n",
    "# nako_labels_c = sorted(glob.glob(f'{processed_dir}/label_cropped/**'))\n",
    "# nako_volumes_c = sorted(glob.glob(f'{processed_dir}/volume_cropped/**'))\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/processed_resized'\n",
    "# ukb_labels_c = sorted(glob.glob(f'{processed_dir}/label_cropped/**'))\n",
    "# ukb_volumes_c = sorted(glob.glob(f'{processed_dir}/volume_cropped/**'))\n",
    "\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/KORA/n4_corrected_2/vol_resized'\n",
    "# # kora_labels_c = sorted(glob.glob(f'{processed_dir}/label_cropped/**'))\n",
    "# kora_volumes_c = sorted(glob.glob(f'{processed_dir}/volume_cropped/**'))\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/NAKO/n4_corrected_2/vol_resized'\n",
    "# # nako_labels_c = sorted(glob.glob(f'{processed_dir}/label_cropped/**'))\n",
    "# nako_volumes_c = sorted(glob.glob(f'{processed_dir}/volume_cropped/**'))\n",
    "# processed_dir = f'{DEFAULT_OUTPUT_PATH}/UKB/n4_corrected_2/vol_resized'\n",
    "# # ukb_labels_c = sorted(glob.glob(f'{processed_dir}/label_cropped/**'))\n",
    "# ukb_volumes_c = sorted(glob.glob(f'{processed_dir}/volume_cropped/**'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_c = ukb_labels_c+nako_labels_c+kora_labels_c\n",
    "volumes_c = ukb_volumes_c+ nako_volumes_c + kora_volumes_c\n",
    "volumes_cf = ukb_volumes_c_f+ nako_volumes_c_f + kora_volumes_c_f\n",
    "volumes_cw = ukb_volumes_c_w+ nako_volumes_c_w + kora_volumes_c_w\n",
    "volumes_cin = ukb_volumes_c_in+ nako_volumes_c_in + kora_volumes_c_in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save(volid, vol_root=f'{processed_dir}/label_cropped', label_root=f'{processed_dir}/volume_cropped', img_save_path = f'{processed_dir}/merged_imgs'):\n",
    "    vol = nb.load(f'{vol_root}/{volid}.nii.gz')\n",
    "    label = nb.load(f'{label_root}/{volid}.nii.gz') if label_root is not None else None\n",
    "\n",
    "    im = vol.get_fdata()\n",
    "    x = im.shape[2]//2\n",
    "    masked = label.get_fdata() if label is not None else None\n",
    "    plt.figure()\n",
    "    plt.imshow(np.rot90(im[:,:,x]), 'gray', interpolation='none')\n",
    "    if masked is not None:\n",
    "        plt.imshow(np.rot90(masked[:,:,x]), 'jet', interpolation='none', alpha=0.5)\n",
    "    plt.savefig(f'{img_save_path}/{volid}.png',  dpi=250, quality=95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in nako_volumes_c:\n",
    "    volid = p.split('/')[-1].split('.')[0]\n",
    "    vol_root= '/'.join(p.split('/')[:-2])+'/volume_resized_cropped'\n",
    "    label_root= '/'.join(p.split('/')[:-2])+'/label_resized_cropped'\n",
    "    img_save_path= '/'.join(p.split('/')[:-3])+'/merged_imgs_axial'\n",
    "    print(volid, vol_root, label_root, img_save_path)\n",
    "    create_if_not(img_save_path)\n",
    "    visualize_and_save(volid, vol_root, label_root, img_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAKO_REFRENCE_IMAGE = '100083 temp/NAKO/processed_resized/volume_cropped temp/NAKO/processed_resized/label_cropped temp/NAKO/merged_imgs'\n",
    "# KORA_REFERENCE_IMAGE = 'KORA2459745 temp/KORA/processed_resized/volume_cropped temp/KORA/processed_resized/label_cropped temp/KORA/merged_imgs'\n",
    "# UKB_REFERENCE_IMAGE= '5934622_20201_2_0 temp/UKB/processed_resized/volume_cropped temp/UKB/processed_resized/label_cropped temp/UKB/merged_imgs'\n",
    "# ALL_REFERENCE_IMAGE='100083 temp/NAKO/processed_resized/volume_cropped temp/NAKO/processed_resized/label_cropped temp/NAKO/merged_imgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def estimate_weights_mfb(labels, no_of_class=9):\n",
    "#     class_weights = np.zeros_like(labels)\n",
    "#     unique, counts = np.unique(labels, return_counts=True)\n",
    "#     median_freq = np.median(counts)\n",
    "#     weights = np.zeros(no_of_class)\n",
    "#     for i, label in enumerate(unique):\n",
    "#         class_weights += (median_freq // counts[i]) * np.array(lab print('vol:', np.argwhere(np.isnan(img.get_fdata())))\n",
    "#             hist_matched_img = hist_match(img, reference_path)\n",
    "#             save_volume(hist_matched_img, f'{new_path}/{phase}/volume_hist{phase_modes[i]}/{vol_id}')\n",
    "#             hist_matched_img_all = hist_match(img, all_reference_path)\n",
    "#             save_volume(hist_matched_img_all, f'{all_path}/{phase}/volume_hist{phase_modes[i]}/{vol_id}')\n",
    "#             print('hist vol:', np.argwhere(np.isnan(hist_matched_img.get_fdata())))\n",
    "#             print('hist vol_all:', np.argwhere(np.isnan(hist_matched_img_all.get_fdata())))\n",
    "            \n",
    "#             intensity_matched_img = intensity_matching(img, reference_path)\n",
    "#             save_volume(intensity_matched_img, f'{new_path}/{phase}/volume_intensity{phase_modes[i]}/{vol_id}')\n",
    "#             intensity_matched_img_all = intensity_matching(img, all_reference_path)\n",
    "#             save_volume(intensity_matched_img_all, f'{all_path}/{phase}/volume_intensity{phase_modes[i]}/{vol_id}') \n",
    "#             print('intensity vol:', np.argwhere(np.isnan(intensity_matched_img.get_fdata())))\n",
    "#             print('intensity vol All:', np.argwhere(np.isnan(intensity_matched_img_all.get_fdata())))els == label)\n",
    "#         weights[int(label)] = median_freq // counts[i]\n",
    "\n",
    "#     grads = np.gradient(labels)\n",
    "#     edge_weights = (grads[0] ** 2 + grads[1] ** 2) > 0\n",
    "#     class_weights += 2 * edge_weights\n",
    "\n",
    "#     return class_weights, weights\n",
    "\n",
    "# def estimate_weights_per_slice(labels, no_of_class=9):\n",
    "#     weights_per_slice = []\n",
    "#     for slice_ in labels:\n",
    "#         unique, counts = np.unique(slice_, return_counts=True)\n",
    "#         median_freq = np.median(counts)\n",
    "#         weights = np.zeros(no_of_class)\n",
    "#         for i, label in enumerate(unique):\n",
    "#             weights[int(label)] = median_freq // counts[i]\n",
    "#         weights_per_slice.append(weights)\n",
    "\n",
    "#     return np.array(weights_per_slice)\n",
    "\n",
    "# def min_max_norm(img):\n",
    "# #     return img\n",
    "#     volume = img.get_fdata()\n",
    "#     volume = (volume - np.min(volume)) / (np.max(volume) - np.min(volume))\n",
    "#     return nb.Nifti1Image(volume, img.affine, img.header)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abhijit/Jyotirmay/abdominal_segmentation/quickNAT_pytorch/create_datasets/datasets/kora/test.txt ['KORA2453290', 'KORA2453666', 'KORA2460408']\n",
      "/home/abhijit/Jyotirmay/abdominal_segmentation/quickNAT_pytorch/create_datasets/datasets/nako/test.txt ['100025', '100035', '100085', '100083']\n",
      "/home/abhijit/Jyotirmay/abdominal_segmentation/quickNAT_pytorch/create_datasets/datasets/ukb/test.txt ['1019631_20201_2_0', '1013391_20201_2_0', '1108214_20201_2_0', '1026125_20201_2_0', '1036900_20201_2_0']\n",
      "['KORA2453290', 'KORA2453666', 'KORA2460408', '100025', '100035', '100085', '100083', '1019631_20201_2_0', '1013391_20201_2_0', '1108214_20201_2_0', '1026125_20201_2_0', '1036900_20201_2_0']\n",
      "0 /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/processed/label_resized_cropped/100112.nii.gz\n",
      "continue\n",
      "1 /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/processed/volume_resized_cropped/100112.nii.gz\n",
      "continue\n",
      "2 /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/processed/volume_f_resized_cropped/100112.nii.gz\n",
      "continue\n",
      "3 /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/processed/volume_w_resized_cropped/100112.nii.gz\n",
      "continue\n",
      "4 /mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/temp2/NAKO/processed/volume_in_resized_cropped/100112.nii.gz\n",
      "continue\n"
     ]
    }
   ],
   "source": [
    "# kora_test = ['KORA2456289', 'KORA2458366', 'KORA2459728', 'KORA2459745']\n",
    "# nako_test = ['100025', '100035', '100085','100083']\n",
    "# ukb_test = ['1019631_20201_2_0','1013391_20201_2_0','1108214_20201_2_0','1026125_20201_2_0','1036900_20201_2_0']\n",
    "\n",
    "phase_modes = {\n",
    "    0: '',\n",
    "    1: '',\n",
    "    2: '_f',\n",
    "    3: '_w',\n",
    "    4: '_in'\n",
    "}\n",
    "references = {\n",
    "    \"KORA\": {\n",
    "        1: f'{DEFAULT_OUTPUT_PATH}/KORA/processed/volume_resized_cropped/KORA2459745.nii.gz',\n",
    "        2: f'{DEFAULT_OUTPUT_PATH}/KORA/processed/volume_f_resized_cropped/KORA2459745.nii.gz',\n",
    "        3: f'{DEFAULT_OUTPUT_PATH}/KORA/processed/volume_w_resized_cropped/KORA2459745.nii.gz',\n",
    "        4: f'{DEFAULT_OUTPUT_PATH}/KORA/processed/volume_in_resized_cropped/KORA2459745.nii.gz',\n",
    "    },\n",
    "    \"NAKO\": {\n",
    "        1: f'{DEFAULT_OUTPUT_PATH}/NAKO/processed/volume_resized_cropped/100083.nii.gz',\n",
    "        2: f'{DEFAULT_OUTPUT_PATH}/NAKO/processed/volume_f_resized_cropped/100083.nii.gz',\n",
    "        3: f'{DEFAULT_OUTPUT_PATH}/NAKO/processed/volume_w_resized_cropped/100083.nii.gz',\n",
    "        4: f'{DEFAULT_OUTPUT_PATH}/NAKO/processed/volume_in_resized_cropped/100083.nii.gz',\n",
    "    },\n",
    "    \"UKB\": {\n",
    "        1: f'{DEFAULT_OUTPUT_PATH}/UKB/processed/volume_resized_cropped/1036900_20201_2_0.nii.gz',\n",
    "        2: f'{DEFAULT_OUTPUT_PATH}/UKB/processed/volume_f_resized_cropped/1036900_20201_2_0.nii.gz',\n",
    "        3: f'{DEFAULT_OUTPUT_PATH}/UKB/processed/volume_w_resized_cropped/1036900_20201_2_0.nii.gz',\n",
    "        4: f'{DEFAULT_OUTPUT_PATH}/UKB/processed/volume_in_resized_cropped/1036900_20201_2_0.nii.gz',\n",
    "    }\n",
    "}\n",
    "\n",
    "kora_test_text = '/home/abhijit/Jyotirmay/abdominal_segmentation/quickNAT_pytorch/create_datasets/datasets/kora/test.txt'\n",
    "nako_test_text = '/home/abhijit/Jyotirmay/abdominal_segmentation/quickNAT_pytorch/create_datasets/datasets/nako/test.txt'\n",
    "ukb_test_text = '/home/abhijit/Jyotirmay/abdominal_segmentation/quickNAT_pytorch/create_datasets/datasets/ukb/test.txt'\n",
    "\n",
    "data_path = '/mnt/nas/Abhijit/Jyotirmay/abdominal_segmentation/dataset5'\n",
    "all_test = []\n",
    "\n",
    "all_test_paths = [kora_test_text, nako_test_text, ukb_test_text]\n",
    "for volumes_txt_file in all_test_paths:\n",
    "    with open(volumes_txt_file) as file_handle:\n",
    "        volumes_to_use = file_handle.read().splitlines()\n",
    "        print(volumes_txt_file, volumes_to_use)\n",
    "        all_test.extend(volumes_to_use)\n",
    "\n",
    "print(all_test)\n",
    "exclude_list = ['KORA2460249', '100006','100008', '1004985_20201_2_0','1108214_20201_2_0',\n",
    "                'KORA2453290','KORA2460734', 'volume']\n",
    "ngb_list = ['KORA2453290', '1108214_20201_2_0', '1584559_20201_2_0', '1002359_20201_2_0', '6025746_20201_2_0', '4627690_20201_2_0',\n",
    "            '100183', '100161']\n",
    "# all_test = kora_test + nako_test + ukb_test\n",
    "# for ps in zip(labels_c,volumes_c,volumes_cf,volumes_cw,volumes_cin):\n",
    "# for ps in zip(kora_labels_c, kora_volumes_c, kora_volumes_c_f, kora_volumes_c_w, kora_volumes_c_in):\n",
    "for ps in zip(nako_labels_c, nako_volumes_c, nako_volumes_c_f, nako_volumes_c_w, nako_volumes_c_in):\n",
    "# for ps in zip(ukb_labels_c, ukb_volumes_c, ukb_volumes_c_f, ukb_volumes_c_w, ukb_volumes_c_in):\n",
    "    for i, p in enumerate(ps):\n",
    "        print(i, p)\n",
    "#         if i >= 2:\n",
    "#             continue\n",
    "        ds = p.split('/')[-4]\n",
    "        vol_id = p.split('/')[-1].split('.')[0]\n",
    "        if vol_id not in ngb_list:\n",
    "            print(\"continue\")\n",
    "            continue\n",
    "        print('Processing: ', vol_id, ds)\n",
    "#         if vol_id in exclude_list:\n",
    "#             print('excluded:', vol_id)\n",
    "#             continue\n",
    "    \n",
    "        if vol_id == 'volume':\n",
    "            continue\n",
    "\n",
    "        if vol_id in all_test:\n",
    "            phase = 'test'\n",
    "        else:\n",
    "            phase = 'train'\n",
    "\n",
    "        new_path = f'{data_path}/{ds}'\n",
    "        all_path = f'{data_path}/ALL'\n",
    "        if i == 0:\n",
    "            label_img = nb.load(p)\n",
    "            save_volume(label_img, f'{new_path}/{phase}/label/{vol_id}')\n",
    "            save_volume(label_img, f'{all_path}/{phase}/label/{vol_id}')\n",
    "        else:\n",
    "            reference_path = None\n",
    "            all_reference_path = references['NAKO'][i]\n",
    "            reference_path = references[ds][i] if ds in references.keys() else None\n",
    "            if reference_path == None:\n",
    "                raise Exception('REFERENCE IS NONE')\n",
    "            else:\n",
    "                print(reference_path, all_reference_path)\n",
    "                \n",
    "            img = nb.load(p)\n",
    "            \n",
    "            save_volume(img, f'{new_path}/{phase}/volume{phase_modes[i]}/{vol_id}')\n",
    "            save_volume(img, f'{all_path}/{phase}/volume{phase_modes[i]}/{vol_id}')\n",
    "#             print('vol:', np.argwhere(np.isnan(img.get_fdata())))\n",
    "            hist_matched_img = hist_match(img, reference_path)\n",
    "            save_volume(hist_matched_img, f'{new_path}/{phase}/volume_hist{phase_modes[i]}/{vol_id}')\n",
    "            hist_matched_img_all = hist_match(img, all_reference_path)\n",
    "            save_volume(hist_matched_img_all, f'{all_path}/{phase}/volume_hist{phase_modes[i]}/{vol_id}')\n",
    "#             print('hist vol:', np.argwhereUKB(np.isnan(hist_matched_img.get_fdata())))\n",
    "#             print('hist vol_all:', np.argwhere(np.isnan(hist_matched_img_all.get_fdata())))\n",
    "            \n",
    "            intensity_matched_img = intensity_matching(img, reference_path)\n",
    "            save_volume(intensity_matched_img, f'{new_path}/{phase}/volume_intensity{phase_modes[i]}/{vol_id}')\n",
    "            intensity_matched_img_all = intensity_matching(img, all_reference_path)\n",
    "            save_volume(intensity_matched_img_all, f'{all_path}/{phase}/volume_intensity{phase_modes[i]}/{vol_id}') \n",
    "#             print('intensity vol:', np.argwhere(np.isnan(intensity_matched_img.get_fdata())))\n",
    "#             print('intensity vol All:', np.argwhere(np.isnan(intensity_matched_img_all.get_fdata())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/nas/Users/Sebastian/UKB/ukb_selected_diabetes_data_matched.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Unnamed: 0'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:remotenv]",
   "language": "python",
   "name": "conda-env-remotenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

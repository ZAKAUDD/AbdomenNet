{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dataset in global_vars.py to NAKO.\n",
    "\n",
    "from global_vars import *\n",
    "from func import *\n",
    "\n",
    "import pickle as p\n",
    "import glob \n",
    "import json\n",
    "import subprocess\n",
    "import getpass\n",
    "import os\n",
    "import ants\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "NAKO_Extreme_Cases = {\n",
    "    'skinniest': '100043',\n",
    "    'fattest': '100081',\n",
    "    'shortest': '100146', \n",
    "    'tallest': '100133'\n",
    "}\n",
    "\n",
    "vol_to_check_list =  ['100006']\n",
    "exclude = []\n",
    "one_time_n4_optimization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \",\".join(os.listdir('/home/abhijit/Jyotirmay/abdominal_segmentation/quickNAT_pytorch/create_datasets/datasets/lablmaps/NAKO'))\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ' '.join(os.listdir(f'{data_dir}/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nako_file_paths(load_from_txt_file=True):\n",
    "    volumes_to_use = []\n",
    "    if load_from_txt_file:\n",
    "        with open(volume_txt_file) as file_handle:\n",
    "                volumes_to_use = file_handle.read().splitlines()\n",
    "    else:\n",
    "        volumes_to_use = [name for name in os.listdir(data_dir)]\n",
    "    \n",
    "    file_paths = {}\n",
    "    \n",
    "    for vol in volumes_to_use:\n",
    "        if (vol_to_check_list is not None and vol not in vol_to_check_list) or (vol == \"\") or (vol in exclude):\n",
    "            continue\n",
    "        opp_paths = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_opp/**[1,2,3].nii.gz') # **_2**\n",
    "        in_paths = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_in/**[1,2,3]_e2.nii.gz')\n",
    "        f_paths = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_F/**[1,2,3].nii.gz')\n",
    "        w_paths = glob.glob(f'{data_dir}/{vol}/{vol}_3D_GRE_TRA_W/**[1,2,3].nii.gz')\n",
    "        \n",
    "        labelmap_paths = glob.glob(f'{label_dir}/{vol}/**')\n",
    "        \n",
    "        vol_madals_paths = dict(\n",
    "        OPP=opp_paths,\n",
    "        IN=in_paths,\n",
    "        F=f_paths,\n",
    "        W=w_paths\n",
    "        )\n",
    "        file_paths[str(vol)]=dict(\n",
    "            VOLUME_PATHS=vol_madals_paths,\n",
    "            LABEL_PATHS=labelmap_paths,\n",
    "        )\n",
    "    return file_paths\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = load_nako_file_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"100006\": {\n",
      "        \"LABEL_PATHS\": [\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Pancreas.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Adrenal gland (left).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nii_Gallbladder.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Liver.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_1.nrrd_Thyroid gland.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/10006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Kidney (right).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/10006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Kidney (left).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Adrenal gland (right).nrrd\"\n",
      "        ],\n",
      "        \"VOLUME_PATHS\": {\n",
      "            \"F\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_3.nii.gz\"\n",
      "            ],\n",
      "            \"IN\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_1_e2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_2_e2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_3_e2.nii.gz\"\n",
      "            ],\n",
      "            \"OPP\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_3.nii.gz\"\n",
      "            ],\n",
      "            \"W\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_3.nii.gz\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " print(json.dumps(file_paths,sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n4 processing part-1 started with 100006...\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -447.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -639.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -867.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "0.0\n",
      "saving directory: temp/NAKO/n4_corrected_2/vol/100006\n",
      "0.0\n",
      "saving directory: temp/NAKO/n4_corrected_2/vol/100006\n",
      "0.0\n",
      "saving directory: temp/NAKO/n4_corrected_2/vol/100006\n"
     ]
    }
   ],
   "source": [
    "# Individual RESCALING.\n",
    "n4_dict = {}\n",
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4 processing part-1 started with {vol}...')\n",
    "    n4_dict[vol] = []\n",
    "    vol_parts = [[file, read_ras(file)] for file in file_paths[vol]['VOLUME_PATHS']['IN']]\n",
    "    for orig_file, in_image in vol_parts:\n",
    "        n4_dict[vol].append(rescale(in_image, vol, orig_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100006': [{'SCALED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled.nii.gz', 'IN_BIAS': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled_bias_field.nii.gz', 'IN_CORRECTED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled_corrected.nii.gz', 'MIN': 10.0, 'MAX': 2503.0, 'OPP_CORRECTED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_corrected.nii.gz'}, {'SCALED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled.nii.gz', 'IN_BIAS': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled_bias_field.nii.gz', 'IN_CORRECTED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled_corrected.nii.gz', 'MIN': 10.0, 'MAX': 1485.0, 'OPP_CORRECTED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_corrected.nii.gz'}, {'SCALED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled.nii.gz', 'IN_BIAS': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled_bias_field.nii.gz', 'IN_CORRECTED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled_corrected.nii.gz', 'MIN': 10.0, 'MAX': 825.0, 'OPP_CORRECTED': 'temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_corrected.nii.gz'}]}\n"
     ]
    }
   ],
   "source": [
    "print(n4_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n4-biasfield-correction starting with 100006...\n",
      "0 temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled.nii.gz\n",
      "1 temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled.nii.gz\n",
      "2 temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4-biasfield-correction starting with {vol}...')\n",
    "    for idx, n4_d in enumerate(n4_dict[vol]):#enumerate(file_paths[vol]['VOLUME_PATHS']['IN']):\n",
    "        \n",
    "        in_file = n4_d['SCALED']\n",
    "        print(idx, in_file)\n",
    "        img = nb.load(in_file)\n",
    "        data = img.get_fdata()\n",
    "        mask = data.copy()\n",
    "        mask[data>100] = 1\n",
    "        mask[data<=100] = 0\n",
    "        \n",
    "        data_ants_img = ants.from_numpy(data, origin=None, spacing=None, direction=None, has_components=False, is_rgb=False)\n",
    "        mask_ant_img = ants.from_numpy(mask)\n",
    "        image_n4 = ants.n4_bias_field_correction(data_ants_img, \n",
    "                                      mask=mask_ant_img,\n",
    "                                      shrink_factor=3,\n",
    "                                      convergence={'iters': [500, 500, 500, 500], 'tol': 1e-03}, \n",
    "                                      spline_param=400, \n",
    "                                      verbose=True, \n",
    "                                      weight_mask=None)\n",
    "        \n",
    "        image_n4_numpy = image_n4.numpy()\n",
    "        \n",
    "        opp_file = file_paths[vol]['VOLUME_PATHS']['OPP'][idx]\n",
    "        opp_img = nb.load(opp_file)\n",
    "        opp_data = opp_img.get_fdata()\n",
    "        biasfield = data/image_n4_numpy\n",
    "        opp_n4 = opp_data/biasfield\n",
    "        \n",
    "        n4_image = nb.Nifti1Image(opp_n4, img.affine, img.header)\n",
    "        new_filename = opp_file.split('/')[-1].split('.')[0]\n",
    "        nb.save(n4_image, f'{n4_corrected_data_dir}/vol/{vol}/{new_filename}_n4_corrected.nii.gz')\n",
    "        n4_dict[vol][idx]['OPP_CORRECTED'] = f'{n4_corrected_data_dir}/vol/{vol}/{new_filename}_n4_corrected.nii.gz'\n",
    "        \n",
    "    file_paths[vol]['N4_1'] = n4_dict[vol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"100006\": {\n",
      "        \"LABEL_PATHS\": [\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Pancreas.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Adrenal gland (left).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nii_Gallbladder.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Liver.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_1.nrrd_Thyroid gland.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/10006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Kidney (right).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/10006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Kidney (left).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Adrenal gland (right).nrrd\"\n",
      "        ],\n",
      "        \"N4_1\": [\n",
      "            {\n",
      "                \"IN_BIAS\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled_bias_field.nii.gz\",\n",
      "                \"IN_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled_corrected.nii.gz\",\n",
      "                \"MAX\": 2503.0,\n",
      "                \"MIN\": 10.0,\n",
      "                \"OPP_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_opp_3D_GRE_TRA_1_n4_corrected.nii.gz\",\n",
      "                \"SCALED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled.nii.gz\"\n",
      "            },\n",
      "            {\n",
      "                \"IN_BIAS\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled_bias_field.nii.gz\",\n",
      "                \"IN_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled_corrected.nii.gz\",\n",
      "                \"MAX\": 1485.0,\n",
      "                \"MIN\": 10.0,\n",
      "                \"OPP_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_opp_3D_GRE_TRA_2_n4_corrected.nii.gz\",\n",
      "                \"SCALED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled.nii.gz\"\n",
      "            },\n",
      "            {\n",
      "                \"IN_BIAS\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled_bias_field.nii.gz\",\n",
      "                \"IN_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled_corrected.nii.gz\",\n",
      "                \"MAX\": 825.0,\n",
      "                \"MIN\": 10.0,\n",
      "                \"OPP_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_opp_3D_GRE_TRA_3_n4_corrected.nii.gz\",\n",
      "                \"SCALED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled.nii.gz\"\n",
      "            }\n",
      "        ],\n",
      "        \"VOLUME_PATHS\": {\n",
      "            \"F\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_3.nii.gz\"\n",
      "            ],\n",
      "            \"IN\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_1_e2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_2_e2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_3_e2.nii.gz\"\n",
      "            ],\n",
      "            \"OPP\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_3.nii.gz\"\n",
      "            ],\n",
      "            \"W\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_3.nii.gz\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " print(json.dumps(file_paths,sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = file_paths['100036']['VOLUME_PATHS']['IN'][0]\n",
    "# print(path)\n",
    "# img = nb.load(path)\n",
    "# data = img.get_fdata()\n",
    "\n",
    "# mask = data.copy()\n",
    "# mask[data>100] = 1\n",
    "# mask[data<=100] = 0\n",
    "# mask_img = nb.Nifti1Image(mask, img.affine, img.header)\n",
    "# print(img.header, mask_img.header)\n",
    "# file_path = f'{n4_corrected_data_dir}/vol/100036/mask.nii.gz'\n",
    "# nb.save(mask_img, file_path)\n",
    "\n",
    "# for i in range(data.shape[0]):\n",
    "#     plt.plot(data[i])\n",
    "#     plt.show()\n",
    "#     plt.imshow(data[i])\n",
    "#     plt.show()\n",
    "#     plt.imshow(mask[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ants\n",
    "# import ants\n",
    "\n",
    "# data_ants_img = ants.from_numpy(data, origin=None, spacing=None, direction=None, has_components=False, is_rgb=False)\n",
    "# mask_ant_img = ants.from_numpy(mask)\n",
    "# image_n4 = ants.n4_bias_field_correction(data_ants_img, \n",
    "#                               mask=None,\n",
    "#                               shrink_factor=3,\n",
    "#                               convergence={'iters': [500, 500, 500, 500], 'tol': 1e-03}, \n",
    "#                               spline_param=400, \n",
    "#                               verbose=True, \n",
    "#                               weight_mask=None)\n",
    "\n",
    "# print(image_n4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(image_n4.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb.save(nb.)\n",
    "\n",
    "# n4_image = nb.Nifti1Image(image_n4.numpy(), img.affine, img.header)\n",
    "# # print(img.header, mask_img.header)\n",
    "# file_path = f'{n4_corrected_data_dir}/vol/100036/n4_img_no_mask.nii.gz'\n",
    "# nb.save(n4_image, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EXECUTE 'sudo sh ./n4-anne.sh' from command line for n4 bais field generation of all in imgs.\n",
    "\n",
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'applying n4 bias field on opp scans of {vol}...')\n",
    "    vol_parts = [[read_ras(opp_file), read_ras(n4_counterpart['IN_BIAS']), opp_file] for opp_file, n4_counterpart in zip(file_paths[vol]['VOLUME_PATHS']['OPP'],n4_dict[vol])]\n",
    "    idx = 0\n",
    "    file_paths[vol]['N4_1'] = []\n",
    "    for opp_img, bias_field_img, opp_file in vol_parts:\n",
    "        file_paths[vol]['N4_1'].append(apply_bias_field(opp_img, bias_field_img, opp_file, n4_dict[vol][idx], vol))\n",
    "        idx+=1\n",
    "#         n4_dict[vol].append(rescale(opp_image, vol, n4_dict[vol]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_vol_stitching_intensify(images, is_label=False):\n",
    "    if len(images) == 1:\n",
    "        return images[0]\n",
    "    elif len(images) == 0:\n",
    "        raise Exception(\"Empty Image List!\")\n",
    "\n",
    "    images_sorted = sorted(images, key=lambda im: im.header['qoffset_z'], reverse=True)\n",
    "    img_0 = images_sorted[0]\n",
    "\n",
    "    mode = 'nearest' if is_label else 'constant'\n",
    "    img_0 = resample_to_output(img_0, TARGET_RESOLUTION, order=3, mode=mode, cval=0.0)\n",
    "#     img_0 = intensity_correction(img_0)\n",
    "\n",
    "    for idx, img_1 in enumerate(images_sorted[1:]):\n",
    "        print(f'{idx}th img for stitching...')\n",
    "        img_1 = resample_to_output(img_1, TARGET_RESOLUTION, order=3, mode=mode, cval=0.0)\n",
    "        target_affine = img_0.affine.copy()\n",
    "        target_affine[2, 3] = img_1.affine[2, 3].copy()\n",
    "        target_shape = img_0.shape[:2] + img_1.shape[2:]\n",
    "        img_1 = resample_from_to(img_1, [target_shape, target_affine])\n",
    "#         img_1 = intensity_correction(img_1)\n",
    "        later = True if idx == 1 else False\n",
    "        img_0 = vol_stitching_intensify(img_0, img_1, later)\n",
    "    return img_0\n",
    "\n",
    "import skimage\n",
    "import skimage.exposure\n",
    "\n",
    "def intensity_correction(img, is_matrix=False):\n",
    "    data = img.get_fdata() if not is_matrix else img\n",
    "    \n",
    "    print(data.min(), data.max())\n",
    "    data = skimage.exposure.rescale_intensity(data, in_range=(data.min(), data.max()), out_range=(0, 255))\n",
    "#     print(data.min(), data.max())\n",
    "#     data = skimage.exposure.adjust_gamma(data, gamma=1.5)\n",
    "\n",
    "#     data = skimage.exposure.adjust_log(data, 1)\n",
    "    \n",
    "    if is_matrix:\n",
    "        return data\n",
    "    else:\n",
    "        return nb.Nifti1Image(data, img.affine, img.header)\n",
    "\n",
    "    \n",
    "def vol_stitching_intensify(im_0, im_1, later=False):\n",
    "    im_0_z = im_0.shape[2]\n",
    "    im_1_z = im_1.shape[2]\n",
    "\n",
    "    # calculate overlap region:\n",
    "    im_0_end = im_0.header['qoffset_z']\n",
    "    im_1_end = im_1.header['qoffset_z']\n",
    "\n",
    "    spacing = im_0.header['pixdim'][3]\n",
    "\n",
    "    im_0_width = im_0_z * spacing\n",
    "    im_1_width = im_1_z * spacing\n",
    "\n",
    "    im_1_start = im_1_end + im_1_width\n",
    "    im_0_start = im_0_end + im_0_width\n",
    "\n",
    "    overlap = abs(im_0_end - im_1_start)\n",
    "\n",
    "    overlap_v = int(round(overlap / spacing))\n",
    "    extra_overlap = 0\n",
    "    new_im_dim = abs(round((abs(im_1_end - im_0_start)) / spacing))\n",
    "\n",
    "    new_img = np.empty([im_0.shape[0], im_0.shape[1], int(new_im_dim)])\n",
    "\n",
    "    intensity_ref_img = new_img.copy()\n",
    "    \n",
    "    im_0_data = im_0.get_fdata()\n",
    "    im_1_data = im_1.get_fdata()\n",
    "    overlap_v += extra_overlap\n",
    "    sigmoid_c = sigmoid(np.linspace(-DEFAULT_LINSPACE, DEFAULT_LINSPACE, overlap_v))\n",
    "    \n",
    "    for l in range(0, overlap_v):\n",
    "        intensity_ref_img[:, :, (im_1_z - overlap_v + l)] = \\\n",
    "            (1 - sigmoid_c[l]) * im_1_data[:, :, (im_1_z - overlap_v) + l] + (sigmoid_c[l]) * im_0_data[:, :, l]\n",
    "    \n",
    "    intensity_ref_img = intensity_ref_img[:, :, im_1_z - overlap_v+2:im_1_z-2]\n",
    "    \n",
    "    ref_img = nb.Nifti1Image(intensity_ref_img, im_1.affine, im_1.header)\n",
    "#     nb.save(ref_img, f'temp/ref{later}.nii.gz')\n",
    "    if later:\n",
    "        im_1_data = intensity_matching(im_1_data, intensity_ref_img) \n",
    "#         im_1_data = skimage.exposure.match_histograms(im_1_data, intensity_ref_img)\n",
    "    else:\n",
    "        im_0_data = intensity_matching(im_0_data, intensity_ref_img) \n",
    "#         im_0_data = skimage.exposure.match_histograms(im_0_data, intensity_ref_img)\n",
    "    \n",
    "    print(new_img.shape, im_0_z, im_1_z, overlap_v)\n",
    "    overlap_v -= extra_overlap\n",
    "    \n",
    "    new_img[:, :, 0:(im_1_z - overlap_v -extra_overlap//2)] = im_1_data[:, :, 0:(im_1_z - overlap_v-extra_overlap//2)]\n",
    "    new_img[:, :, im_1_z+extra_overlap//2:] = im_0_data[:, :, overlap_v+extra_overlap//2:]\n",
    "    # overlap region:\n",
    "    overlap_v += extra_overlap\n",
    "    for l in range(0, overlap_v):\n",
    "        new_img[:, :, (im_1_z - overlap_v + l)] = \\\n",
    "            (1 - sigmoid_c[l]) * im_1_data[:, :, (im_1_z - overlap_v) + l] + (sigmoid_c[l]) * im_0_data[:, :, l]\n",
    "    overlap_v -= extra_overlap\n",
    "    stitched_img = nb.Nifti1Image(new_img, im_1.affine, im_1.header)\n",
    "    return stitched_img\n",
    "\n",
    "\n",
    "def hist_match(img_data, ref_data):\n",
    "#     template_file = nb.load(histogram_matching_reference_path)\n",
    "    template = ref_data #template_file.get_fdata()\n",
    "    volume = img_data\n",
    "    oldshape = volume.shape\n",
    "    source = volume.ravel()\n",
    "    template = template.ravel()\n",
    "\n",
    "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True, return_counts=True)\n",
    "    t_values, t_counts = np.unique(template, return_counts=True)\n",
    "\n",
    "    s_quantiles = np.cumsum(s_counts).astype(np.float64)\n",
    "    s_quantiles /= s_quantiles[-1]\n",
    "    t_quantiles = np.cumsum(t_counts).astype(np.float64)\n",
    "    t_quantiles /= t_quantiles[-1]\n",
    "\n",
    "    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n",
    "\n",
    "    return interp_t_values[bin_idx].reshape(oldshape)\n",
    "\n",
    "def intensity_matching(img_data, ref_data):\n",
    "#     return img_data\n",
    "    volume = img_data\n",
    "    template = ref_data\n",
    "    m_i = np.mean(volume)\n",
    "    m_r = np.mean(template)\n",
    "    s_i = np.std(volume)\n",
    "    s_r = np.std(template)\n",
    "    hist_mapped_volume = (volume - m_i) * s_r / s_i + m_r\n",
    "    return hist_mapped_volume # nb.Nifti1Image(hist_mapped_volume, img.affine, img.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started with 100006...\n",
      "processing OPP\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -447.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -639.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -867.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "0th img for stitching...\n",
      "(226, 184, 160) 96 96 32\n",
      "1th img for stitching...\n",
      "(226, 184, 236) 160 88 12\n",
      "saving directory: temp/NAKO/n4_corrected_2/vol/100006\n",
      "processing IN\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -447.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -639.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -867.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "0th img for stitching...\n",
      "(226, 184, 160) 96 96 32\n",
      "1th img for stitching...\n",
      "(226, 184, 236) 160 88 12\n",
      "saving directory: temp/NAKO/n4_corrected_2/vol/100006\n",
      "processing F\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -447.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -639.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -867.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "0th img for stitching...\n",
      "(226, 184, 160) 96 96 32\n",
      "1th img for stitching...\n",
      "(226, 184, 236) 160 88 12\n",
      "saving directory: temp/NAKO/n4_corrected_2/vol/100006\n",
      "processing W\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -447.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -639.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 96)\n",
      "Transforming Images to RAS.....\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   1.40625    0.         0.      -203.59375]\n",
      " [   0.         1.40625    0.      -178.90625]\n",
      " [   0.         0.         3.      -867.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (320, 260, 88)\n",
      "Transforming Images to RAS.....\n",
      "0th img for stitching...\n",
      "(226, 184, 160) 96 96 32\n",
      "1th img for stitching...\n",
      "(226, 184, 236) 160 88 12\n",
      "saving directory: temp/NAKO/n4_corrected_2/vol/100006\n"
     ]
    }
   ],
   "source": [
    "# STITCHING VOL PARTS HERE\n",
    "for vol in file_paths.keys():\n",
    "    print(f'started with {vol}...')\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    create_if_not(f'{n4_corrected_data_dir}/vol/{vol}')\n",
    "    file_paths[vol]['ONE'] = {}\n",
    "#     file_paths[vol]['ONE_ORIG'] = {}\n",
    "    for modality_key in file_paths[vol]['VOLUME_PATHS'].keys():\n",
    "        print(f\"processing {modality_key}\")\n",
    "        orig_modal_key = modality_key\n",
    "        if one_time_n4_optimization:\n",
    "            vol_parts = [read_ras(file) for file in file_paths[vol]['VOLUME_PATHS'][modality_key]]\n",
    "        else:\n",
    "            if modality_key == 'OPP':\n",
    "                vol_parts = [read_ras(data_dict['OPP_CORRECTED']) for data_dict in file_paths[vol]['N4_1']]\n",
    "                modality_key = modality_key+'_n4_corrected'\n",
    "            else:\n",
    "                vol_parts = [read_ras(file) for file in file_paths[vol]['VOLUME_PATHS'][modality_key]]\n",
    "\n",
    "        ras_stitched = multi_vol_stitching_intensify(vol_parts)\n",
    "        save_volume(ras_stitched, f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched')\n",
    "#         save_volume(ras_stitched_orig, f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched_orig')\n",
    "        file_paths[vol]['ONE'][f'{orig_modal_key}'] = f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched.nii.gz'\n",
    "#         file_paths[vol]['ONE_ORIG'][f'{orig_modal_key}'] = f'{n4_corrected_data_dir}/vol/{vol}/{modality_key}_ras_stitched_orig.nii.gz'\n",
    "\n",
    "# 192 - 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n4 processing part-2 started with 100006...\n",
      "Reading Files.....\n",
      "Reading Nifti Files.....\n",
      "Affine:[[   2.         0.         0.      -203.59375]\n",
      " [   0.         2.         0.      -178.90625]\n",
      " [   0.         0.         3.      -867.5    ]\n",
      " [   0.         0.         0.         1.     ]], Image Shape: (226, 184, 236)\n",
      "Transforming Images to RAS.....\n",
      "-116.251953125\n",
      "neagtive value detected\n",
      "saving directory: temp/NAKO/n4_corrected_2/vol/100006\n"
     ]
    }
   ],
   "source": [
    "# RESCALING INTENSITIES OF STITCHED VOLUME ABOVE 0\n",
    "n4_dict = {}\n",
    "for vol in file_paths.keys():\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4 processing part-2 started with {vol}...')\n",
    "    n4_dict[vol] = {}\n",
    "    in_stitched_file_path, in_stitched_img = file_paths[vol]['ONE']['IN'], read_ras(file_paths[vol]['ONE']['IN'])\n",
    "    n4_dict[vol]['N4_2'] = rescale(in_stitched_img, vol, in_stitched_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp/NAKO/n4_corrected_2/vol/100006/IN_ras_stitched_n4_scaled.nii.gz'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n4_dict[vol]['N4_2']['SCALED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"100006\": {\n",
      "        \"LABEL_PATHS\": [\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Pancreas.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Adrenal gland (left).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nii_Gallbladder.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Liver.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_1.nrrd_Thyroid gland.nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/10006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Kidney (right).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/10006_3D_GRE_TRA_opp_3D_GRE_TRA_2_Kidney (left).nrrd\",\n",
      "            \"datasets/lablmaps/NAKO/100006/100006_3D_GRE_TRA_opp_3D_GRE_TRA_2.nrrd_Adrenal gland (right).nrrd\"\n",
      "        ],\n",
      "        \"N4_1\": [\n",
      "            {\n",
      "                \"IN_BIAS\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled_bias_field.nii.gz\",\n",
      "                \"IN_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled_corrected.nii.gz\",\n",
      "                \"MAX\": 2503.0,\n",
      "                \"MIN\": 10.0,\n",
      "                \"OPP_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_opp_3D_GRE_TRA_1_n4_corrected.nii.gz\",\n",
      "                \"SCALED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_1_e2_n4_scaled.nii.gz\"\n",
      "            },\n",
      "            {\n",
      "                \"IN_BIAS\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled_bias_field.nii.gz\",\n",
      "                \"IN_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled_corrected.nii.gz\",\n",
      "                \"MAX\": 1485.0,\n",
      "                \"MIN\": 10.0,\n",
      "                \"OPP_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_opp_3D_GRE_TRA_2_n4_corrected.nii.gz\",\n",
      "                \"SCALED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_2_e2_n4_scaled.nii.gz\"\n",
      "            },\n",
      "            {\n",
      "                \"IN_BIAS\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled_bias_field.nii.gz\",\n",
      "                \"IN_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled_corrected.nii.gz\",\n",
      "                \"MAX\": 825.0,\n",
      "                \"MIN\": 10.0,\n",
      "                \"OPP_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_opp_3D_GRE_TRA_3_n4_corrected.nii.gz\",\n",
      "                \"SCALED\": \"temp/NAKO/n4_corrected_2/vol/100006/3D_GRE_TRA_in_3D_GRE_TRA_3_e2_n4_scaled.nii.gz\"\n",
      "            }\n",
      "        ],\n",
      "        \"N4_2\": {\n",
      "            \"N4_2\": {\n",
      "                \"IN_BIAS\": \"temp/NAKO/n4_corrected_2/vol/100006/IN_ras_stitched_n4_scaled_bias_field.nii.gz\",\n",
      "                \"IN_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/IN_ras_stitched_n4_scaled_corrected.nii.gz\",\n",
      "                \"MAX\": 2432.7940852195024,\n",
      "                \"MIN\": 10.0,\n",
      "                \"OPP_CORRECTED\": \"temp/NAKO/n4_corrected_2/vol/100006/OPP_n4_corrected_ras_stitched_n4_corrected.nii.gz\",\n",
      "                \"SCALED\": \"temp/NAKO/n4_corrected_2/vol/100006/IN_ras_stitched_n4_scaled.nii.gz\"\n",
      "            }\n",
      "        },\n",
      "        \"ONE\": {\n",
      "            \"F\": \"temp/NAKO/n4_corrected_2/vol/100006/F_ras_stitched.nii.gz\",\n",
      "            \"IN\": \"temp/NAKO/n4_corrected_2/vol/100006/IN_ras_stitched.nii.gz\",\n",
      "            \"OPP\": \"temp/NAKO/n4_corrected_2/vol/100006/OPP_n4_corrected_ras_stitched.nii.gz\",\n",
      "            \"W\": \"temp/NAKO/n4_corrected_2/vol/100006/W_ras_stitched.nii.gz\"\n",
      "        },\n",
      "        \"VOLUME_PATHS\": {\n",
      "            \"F\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_F/3D_GRE_TRA_F_3D_GRE_TRA_3.nii.gz\"\n",
      "            ],\n",
      "            \"IN\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_1_e2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_2_e2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_in/3D_GRE_TRA_in_3D_GRE_TRA_3_e2.nii.gz\"\n",
      "            ],\n",
      "            \"OPP\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_opp/3D_GRE_TRA_opp_3D_GRE_TRA_3.nii.gz\"\n",
      "            ],\n",
      "            \"W\": [\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_1.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_2.nii.gz\",\n",
      "                \"/home/abhijit/nas_drive/Data_WholeBody/NAKO/NAKO_200/MRI/100006/100006_3D_GRE_TRA_W/3D_GRE_TRA_W_3D_GRE_TRA_3.nii.gz\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " print(json.dumps(file_paths,sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n4-biasfield-correction starting with 100006...\n",
      "temp/NAKO/n4_corrected_2/vol/100006/IN_ras_stitched_n4_scaled.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for vol in file_paths.keys():\n",
    "    if one_time_n4_optimization:\n",
    "        break\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'n4-biasfield-correction starting with {vol}...')\n",
    "#     for idx, opp_file in enumerate(file_paths[vol]['VOLUME_PATHS']['OPP']):\n",
    "    in_file = n4_dict[vol]['N4_2']['SCALED'] #file_paths[vol]['ONE']['IN']\n",
    "    print(in_file)\n",
    "    img = nb.load(in_file)\n",
    "    data = img.get_fdata()\n",
    "    mask = data.copy()\n",
    "    mask[data>100] = 1\n",
    "    mask[data<=100] = 0\n",
    "\n",
    "    data_ants_img = ants.from_numpy(data, origin=None, spacing=None, direction=None, has_components=False, is_rgb=False)\n",
    "    mask_ant_img = ants.from_numpy(mask)\n",
    "    image_n4 = ants.n4_bias_field_correction(data_ants_img, \n",
    "                                  mask=mask_ant_img,\n",
    "                                  shrink_factor=3,\n",
    "                                  convergence={'iters': [500, 500, 500, 500], 'tol': 1e-03}, \n",
    "                                  spline_param=400, \n",
    "                                  verbose=True, \n",
    "                                  weight_mask=None)\n",
    "\n",
    "    image_n4_numpy = image_n4.numpy()\n",
    "    \n",
    "    opp_file = file_paths[vol]['ONE']['OPP']\n",
    "    opp_img = nb.load(opp_file)\n",
    "    opp_data = opp_img.get_fdata()\n",
    "    biasfield = data/image_n4_numpy\n",
    "    opp_n4 = opp_data/biasfield\n",
    "    \n",
    "    n4_image = nb.Nifti1Image(opp_n4, img.affine, img.header)\n",
    "    new_filename = opp_file.split('/')[-1].split('.')[0]\n",
    "    nb.save(n4_image, f'{n4_corrected_data_dir}/vol/{vol}/{new_filename}_n4_corrected.nii.gz')\n",
    "    \n",
    "    n4_dict[vol]['N4_2']['OPP_CORRECTED'] = f'{n4_corrected_data_dir}/vol/{vol}/{new_filename}_n4_corrected.nii.gz'\n",
    "    file_paths[vol]['N4_2'] = n4_dict[vol]['N4_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO: EXECUTE 'sudo sh ./n4-anne-2.sh' from command line for n4 bais field generation of all in imgs.\n",
    "for vol in file_paths.keys():\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    print(f'applying n4 bias field on stitched opp scans of {vol}...')\n",
    "\n",
    "    opp_file = file_paths[vol]['ONE']['OPP']\n",
    "    \n",
    "    n4_counterpart = n4_dict[vol]['N4_2']\n",
    "    print(opp_file, n4_counterpart['IN_BIAS'])\n",
    "    opp_img = read_ras(opp_file)\n",
    "    bias_field_img = read_ras(n4_counterpart['IN_BIAS'])\n",
    "\n",
    "    file_paths[vol]['N4_2'] = apply_bias_field(opp_img, bias_field_img, opp_file, n4_dict[vol]['N4_2'], vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nako_file_paths.p', 'wb') as handle:\n",
    "    p.dump(file_paths, handle, protocol=p.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nako_file_paths.p', 'rb') as handle:\n",
    "    file_paths = p.load(handle)\n",
    "    \n",
    "print(json.dumps(file_paths, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nako_vol_label_fix(vol, label):\n",
    "    vol_vol = np.product(vol.shape)\n",
    "    label_vol = np.product(label.shape)\n",
    "    \n",
    "    world_shape = np.max(np.array([list(vol.shape), list(label.shape)]), axis=0)\n",
    "    print(tuple(world_shape))\n",
    "    final_label = np.zeros(tuple(world_shape))\n",
    "\n",
    "    label_affine = label.affine\n",
    "    vol_affine = vol.affine\n",
    "    if(vol_vol>label_vol):\n",
    "#         final_label = np.zeros(vol.shape)\n",
    "        target_affine = vol_affine\n",
    "        target_header = vol.header\n",
    "        target_dim_v = vol.shape\n",
    "        \n",
    "#         labelmap2vol = npl.inv(target_affine).dot(label_affine)\n",
    "#         start_inv = np.floor(apply_affine(labelmap2vol, [0,0,0])).astype(np.int32)\n",
    "#         sx, sy,sz = start_inv\n",
    "#         end_inv = apply_affine(labelmap2vol, target_dim_v).astype(np.int32)\n",
    "#         final_label = np.zeros(end_inv)\n",
    "#         ex, ey, ez = end_inv\n",
    "#         print(\"seg start inv v: \",start_inv , \"segm end inv v:\",end_inv)\n",
    "        sx,sy,sz,ex,ey,ez = np.abs(get_points(label, vol))\n",
    "        print(sx,sy,sz,ex,ey,ez)\n",
    "        final_label[0:ex+sx, 0:ey+sy, sz:ez] = label.get_fdata()\n",
    "        final_label = np.flip(final_label, axis=0)\n",
    "        final_label = np.flip(final_label, axis=1)\n",
    "        final_label_img = nb.Nifti1Image(final_label, target_affine, target_header)\n",
    "        volume, label = vol, final_label_img\n",
    "    else:\n",
    "#         final_label = np.zeros(label.shape)\n",
    "        target_affine = label_affine\n",
    "        target_header = label.header\n",
    "        target_dim_v = label.shape\n",
    "        \n",
    "#         labelmap2vol = npl.inv(target_affine).dot(vol_affine)\n",
    "#         start_inv = np.floor(apply_affine(labelmap2vol, [0,0,0])).astype(np.int32)\n",
    "#         sx, sy,sz = start_inv\n",
    "#         end_inv = apply_affine(labelmap2vol, target_dim_v).astype(np.int32)\n",
    "#         final_label = np.zeros(end_inv)\n",
    "#         ex, ey, ez = end_inv\n",
    "#         print(\"seg start inv v: \",start_inv , \"segm end inv v:\",end_inv)\n",
    "        sx,sy,sz,ex,ey,ez = np.abs(get_points(vol, label))\n",
    "        print(sx,sy,sz,ex,ey,ez)\n",
    "        final_label = np.flip(final_label, axis=0)\n",
    "        final_label = np.flip(final_label, axis=1)\n",
    "        final_label[0:ex+sx, 0:ey+sy, sz:ez] = vol.get_fdata()\n",
    "        \n",
    "        final_label_img = nb.Nifti1Image(final_label, target_affine, target_header)\n",
    "        volume, label = final_label_img, label\n",
    "    \n",
    "    return volume, label\n",
    "\n",
    "def get_freequent_shape(arr, axis=0):\n",
    "    arr = np.array(arr)\n",
    "    print(arr)\n",
    "    u, indices = np.unique(arr, return_inverse=True)\n",
    "    f_shape = u[np.argmax(np.apply_along_axis(np.bincount, axis, indices.reshape(arr.shape),\n",
    "                                    None, np.max(indices) + 1), axis=axis)]\n",
    "    print(f_shape)\n",
    "    return f_shape\n",
    "\n",
    "def label_parts(label_parts, reference_labelmap=None):\n",
    "    stitched_label = None\n",
    "    mode = 'constant'\n",
    "    order = 0\n",
    "    if reference_labelmap is None:\n",
    "        label_shape = get_freequent_shape([img.shape for img, _, _ in label_parts])##np.max([img.shape for img, _, _ in label_parts], axis=0)\n",
    "        reference_labelmap = [img for img, _, _ in label_parts if list(img.shape) == list(label_shape)][0]\n",
    "    else:\n",
    "        label_shape = reference_labelmap.shape\n",
    "    print('final_label_stitching shape:',label_shape)\n",
    "    print('reference label shape:', len(label_parts), reference_labelmap.shape)\n",
    "    stitched_label = np.zeros(label_shape)\n",
    "    for labelmap_img, lidx, lname in label_parts:\n",
    "        print('lp:bfr:', lidx, lname, labelmap_img.shape, np.unique(labelmap_img.get_fdata()))\n",
    "        labelmap_img = makeit_3d(labelmap_img)\n",
    "        labelmap_img = resample_from_to(labelmap_img, [label_shape, reference_labelmap.affine], order=order, mode=mode, cval=0)\n",
    "        \n",
    "        print(np.unique(labelmap_img.get_fdata()), labelmap_img.shape)\n",
    "        \n",
    "        sx,sy,sz,ex,ey,ez = get_points(labelmap_img, reference_labelmap)\n",
    "        sx,sy,sz,ex,ey,ez = np.abs([sx,sy,sz,ex,ey,ez])\n",
    "        print('label_points:', sx,sy,sz,ex,ey,ez)\n",
    "        \n",
    "        labelmap = labelmap_img.get_fdata()\n",
    "        labelmap = np.multiply(lidx, labelmap)\n",
    "        x, y, z = labelmap.shape\n",
    "        stitched_label[0:ex+sx, 0:ey+sy, 0:ez+sz] += labelmap\n",
    "        print(\"###############################################################################################\") \n",
    "        \n",
    "    labelmap = np.round(stitched_label)\n",
    "    stitched_labeled_img = nb.Nifti1Image(labelmap, reference_labelmap.affine, reference_labelmap.header)\n",
    "    \n",
    "    return stitched_labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STARTING NAKO LABEL-MAPS.\")\n",
    "print('Reading Label Maps.....')\n",
    "for vol in file_paths.keys():\n",
    "    print(vol)\n",
    "    if vol_to_check_list is not None and vol not in vol_to_check_list:\n",
    "        continue\n",
    "    later = None\n",
    "    print(file_paths[vol]['LABEL_PATHS'])\n",
    "    if len(file_paths[vol]['LABEL_PATHS']) == 0:\n",
    "        print(f\"#################### ALERT:: NO LABELPATHS IN THE DICTIONARY FOR {vol} #########################\")\n",
    "        continue\n",
    "#     volume = nb.load(file_paths[vol]['N4_2']['OPP_CORRECTED'])\n",
    "    volume = nb.load(file_paths[vol]['ONE']['OPP'])\n",
    "    img_ras_list = []\n",
    "    for label_file_to_read in file_paths[vol]['LABEL_PATHS']:\n",
    "        img_ras, lidx, labelname = read_ras(label_file_to_read, is_label=True)\n",
    "        if labelname is None or img_ras is None:\n",
    "            continue\n",
    "        print(img_ras.shape)\n",
    "        img_ras = makeit_3d(img_ras)\n",
    "        print('After 3d confirmed:', img_ras.shape)\n",
    "        mode='constant'\n",
    "        img_ras = resample_to_output(img_ras, TARGET_RESOLUTION, order=0, mode=mode, cval=0)\n",
    "        img_ras = labels_integerify(img_ras)\n",
    "    #     img_ras = resample_from_to(img_ras, [volume.shape, img_ras.affine])\n",
    "        if labelname == 'SPLEEN':\n",
    "            later = [img_ras, lidx, labelname]\n",
    "        else:\n",
    "            img_ras_list.append([img_ras, lidx, labelname])\n",
    "    if later is not None:\n",
    "        img_ras_list.append(later)\n",
    "    s_label = label_parts(img_ras_list)\n",
    "    volume, s_label = nako_vol_label_fix(volume, s_label)\n",
    "    #     volume, stitched_label = combine_nako_seg(file_paths[vol]['LABEL_PATHS'],'' ,file_paths[vol]['N4_2']['OPP_CORRECTED'])\n",
    "\n",
    "    print('Viewing Stitched Images.....')\n",
    "    volume_3_view_viewer(get_volume_data(volume))\n",
    "\n",
    "    volume_3_view_viewer(get_volume_data(s_label))\n",
    "\n",
    "    print('Saving Processed & Stitched Image.....')\n",
    "    save_volume(volume, f'{processed_dir}/volume/{vol}')\n",
    "    save_volume(s_label, f'{processed_dir}/label/{vol}')\n",
    "    print('FINISHED.')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_overlay(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dict= \n",
    "# {\n",
    "#     VOL_ID: {\n",
    "#         VOLUME_PATHS: {\n",
    "#             OPP: [],\n",
    "#             IN: [],\n",
    "#             F: [],\n",
    "#             W: []\n",
    "#         },\n",
    "#         LABEL_PATHS: [],\n",
    "#         N4_1: [\n",
    "#             {\n",
    "#                 SCALED: f'{n4_corrected_data_dir}/vol/{vol_id}/{new_filename}_n4_scaled.nii.gz',\n",
    "#                 IN_BIAS: f'{n4_corrected_data_dir}/vol/{vol_id}/{new_filename}_n4_scaled_bias_field.nii.gz',\n",
    "#                 IN_CORRECTED: f'{n4_corrected_data_dir}/vol/{vol_id}/{new_filename}_n4_scaled_corrected.nii.gz',\n",
    "#                 OPP_CORRECTED: '',\n",
    "#                 MIN: u_min,\n",
    "#                 MAX: u_max\n",
    "#             },\n",
    "#             {},\n",
    "#             {}\n",
    "#         ],\n",
    "#         ONE: {\n",
    "#             OPP: '',\n",
    "#             IN: '',\n",
    "#             F: '',\n",
    "#             W: '',\n",
    "#         },\n",
    "#         N4_2: {\n",
    "#             SCALED: f'{n4_corrected_data_dir}/vol/{vol_id}/{new_filename}_n4_scaled.nii.gz',\n",
    "#             IN_BIAS: f'{n4_corrected_data_dir}/vol/{vol_id}/{new_filename}_n4_scaled_bias_field.nii.gz',\n",
    "#             IN_CORRECTED: f'{n4_corrected_data_dir}/vol/{vol_id}/{new_filename}_n4_scaled_corrected.nii.gz',\n",
    "#             OPP_CORRECTED: '',\n",
    "#             MIN: u_min,\n",
    "#             MAX: u_max\n",
    "#         },\n",
    "        \n",
    "#     }\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

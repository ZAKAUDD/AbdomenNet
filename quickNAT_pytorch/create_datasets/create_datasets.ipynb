{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess abdominal MRI data from 3 datasets (KORA, NAKO, UKB) \n",
    "\n",
    "### preprocessing steps:\n",
    "1. combine scans for UKB -- separate .ipynb for that part. (since UKB is split into different scans for the abdomen. differs between scans, but most have 2 scans (upper and lower abdomen) that are relevant for us. combination with simple linear function in the overlap part. so far all scans have to be manually checked after the combination.\n",
    "2. combine segmentations --> see separate .ipynb for that part. (also handling different shapes of segmentations, different orientations, overlaps etc). Output of this step are image scans (input_scan.nii.gz and combined segmentation map: combined_segmentation.nii.gz, all in RAS orientation)\n",
    "3. this file: preprocessing 1: loads the datasets KORA, UKB or NAKO (or all 3), and resamples them to a common resolution of 2,2,3mm \n",
    "4. preprocessing 2: loads resampled files and normalizes the images by min max normalization. Then saves these images as nii files.\n",
    "\n",
    "Next step would be creating h5 files to train the quickNat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nibabel  # for loading and saving nifty files\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Pad\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nrrd\n",
    "from nibabel.affines import from_matvec, to_matvec, apply_affine\n",
    "\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labels:\n",
    "\n",
    "liver = 1  \n",
    "spleen = 2  \n",
    "kidney_r = 3  \n",
    "kidney_l = 4  \n",
    "adrenal_r = 5  \n",
    "adrenal_l = 6  \n",
    "pancreas = 7  \n",
    "gallbladder = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load datasets:\n",
    "\n",
    "directory structure should be like: .../datasets/dataID/data/patID/input_scan.nii.gz and   .../datasets/dataID/data/patID/combined_segmentation.nii.gz  \n",
    "    \n",
    "where dataID = KORA, NAKO or UKB  \n",
    "patIDs for training are in ../datasets/dataID/dataID.train  \n",
    "e.g. for KORA: .../datasets/KORA/KORA.train  \n",
    "\n",
    "this has to be run separately for train, test and val split that are indicated in dataID.train, dataID.val, dataID.test files  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c455e2f10e85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m              'UKB' : []}\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KORA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# read filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/anne/phd/projects/whole_body/whole_body_segmentation/quickNAT_pytorch/create_datasets/'\n",
    "all_images_train = {'KORA': [],\n",
    "             'NAKO': [],\n",
    "             'UKB' : []}\n",
    "all_pat_ids = {'KORA': [],\n",
    "             'NAKO': [],\n",
    "             'UKB' : []}\n",
    "for i, data_id in enumerate(['KORA']):\n",
    "    data_dir = os.path.join(root_dir, data_id, 'data')\n",
    "    filenames = os.path.join(root_dir, data_id, data_id+'.test')\n",
    "    # read filenames\n",
    "    with open(filenames) as f:\n",
    "        pat_ids = f.read().splitlines()   \n",
    "    all_pat_ids[data_id] = pat_ids\n",
    "\n",
    "    print(pat_ids)\n",
    "    for folder in pat_ids:\n",
    "        seg_dir = os.path.join(data_dir,folder)\n",
    "        #listFiles = os.listdir(seg_dir)\n",
    "        #seg_files = [f for f in listFiles if \"input_scan\" in f or 'combined_segmentation' in f]\n",
    "        try:\n",
    "            img = nibabel.load(os.path.join(seg_dir,'input_scan.nii.gz'))\n",
    "            segm = nibabel.load(os.path.join(seg_dir,'combined_segmentation.nii.gz'))\n",
    "            \n",
    "            print(segm.get_fdata().dtype)\n",
    "            segm_test = segm.get_fdata().astype('int')\n",
    "            print(segm_test.dtype)\n",
    "        except FileNotFoundError as err:\n",
    "            print('did not find input scan AND segmentation for patient id: ', folder)\n",
    "            print(err)\n",
    "        \n",
    "        all_images_train[data_id].append((img,segm))\n",
    "#print(all_images_train)\n",
    "print(all_pat_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing 1 (resampling) can be skipped. if already resampled proceed with preprocessing 2\n",
    "\n",
    "first checks if segmentations have no overlaps  \n",
    "if overlaps are found than this needs to be handled first  \n",
    "then resamples the images to 2,2,3mm resolution --> takes a while\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KORA\n",
      "0.0\n",
      "8.0\n",
      "no overlaps in segmentation\n",
      "min intensity:  0.0\n",
      "max intensity:  863.0\n",
      "steps:  [1.6666666 1.6666666 1.699997 ]\n",
      "21388\n",
      "8418\n",
      "8418\n",
      "shape before:  (240, 133, 163)\n",
      "shape after:  (256, 256, 128)\n",
      "AFFINE:  [[   2.            0.            0.         -261.92883301]\n",
      " [   0.            2.            0.          210.32397461]\n",
      " [   0.            0.            3.          -97.33310699]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "NAKO\n",
      "UKB\n"
     ]
    }
   ],
   "source": [
    "for i, data_id in enumerate(['KORA', 'NAKO', 'UKB']):\n",
    "    print(data_id)\n",
    "    images = all_images_train[data_id]\n",
    "\n",
    "    #ax = plt.hist(images.ravel(), bins = 256)\n",
    "    #plt.show()\n",
    "    for j, imgs in enumerate(images):\n",
    "        img_data = imgs[0].get_fdata()\n",
    "        img_header = imgs[0].header\n",
    "        segm_data = imgs[1].get_fdata()\n",
    "        segm_header = imgs[1].header\n",
    "        print(np.min(segm_data))\n",
    "        print(np.max(segm_data))\n",
    "        if np.max(segm_data) > 8:\n",
    "            print('max bigger than 8 for: ', data_id, all_pat_ids[data_id][j] )\n",
    "            print ('max: ', np.max(segm_data))          \n",
    "            print(np.where(segm_data==np.max(segm_data)))\n",
    "        else:\n",
    "            print('no overlaps in segmentation')\n",
    "        \n",
    "        print('min intensity: ', np.min(img_data))\n",
    "        print('max intensity: ', np.max(img_data))\n",
    "        \n",
    "        steps = img_header['pixdim'][1:4]\n",
    "        target_voxel_dim = [2,2,3]\n",
    "        print('steps: ', steps)\n",
    "        \n",
    "        segm_data = segm_data.astype('int')\n",
    "        \n",
    "        print(np.sum(segm_data == 4))\n",
    "        if data_id == 'KORA':\n",
    "            img_data = np.flip(np.moveaxis(img_data, 2, 1))  # 012 -> 021\n",
    "            segm_data = np.flip(np.moveaxis(segm_data, 2, 1))  # 012 -> 021\n",
    "            \n",
    "        img_data, img_header = do_interpolate(img_data, steps, img_header, target_voxel_dim)\n",
    "        segm_data, segm_header = do_interpolate(segm_data, steps, segm_header, target_voxel_dim, is_label=True)\n",
    "        print(np.sum(segm_data == 4))\n",
    "        #print(np.unique(segm_data))\n",
    "        \n",
    "        segm_data = segm_data.astype('int')\n",
    "        print(np.sum(segm_data == 4))\n",
    "\n",
    "        \n",
    "        print('shape before: ', img_data.shape)\n",
    "        # now reshape the input scans to a target dimension dim % 16 = 0 so all images have the same shape\n",
    "        target_dim = [256,256,128]\n",
    "\n",
    "        img_data, segm_data = post_interpolate(img_data, labelmap=segm_data, target_shape=target_dim)\n",
    "        \n",
    "        print('shape after: ', img_data.shape)\n",
    "        img_header['dim'][1:4] = img_data.shape\n",
    "        segm_header['dim'][1:4] = segm_data.shape\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        print('AFFINE: ', img_header.get_best_affine())\n",
    "        #save images:\n",
    "        \n",
    "        #new_img_nii = nibabel.Nifti1Image(img_data, img_header.get_best_affine(), img_header)\n",
    "        new_img_nii = nibabel.MGHImage(img_data, img_header.get_best_affine(), img_header)\n",
    "        new_file_path = os.path.join(root_dir,data_id,'data', all_pat_ids[data_id][j],'resampled_image.nii.gz')\n",
    "        nibabel.save(new_img_nii, new_file_path)\n",
    "        \n",
    "        #new_img_nii = nibabel.Nifti1Image(segm_data, segm_header.get_best_affine(), segm_header)\n",
    "        new_img_nii = nibabel.MGHImage(segm_data, segm_header.get_best_affine(), segm_header)\n",
    "        new_img_nii.set_data_dtype('uint8')\n",
    "        new_file_path = os.path.join(root_dir,data_id,'data', all_pat_ids[data_id][j],'resampled_segm.nii.gz')\n",
    "        nibabel.save(new_img_nii, new_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing 2\n",
    "\n",
    "scale the pixel values between 0 and 1 (min max normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data again (this time load the resampled scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2460249']\n",
      "{'KORA': ['2460249'], 'NAKO': [], 'UKB': []}\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/anne/phd/projects/whole_body/whole_body_segmentation/quickNAT_pytorch/create_datasets/'\n",
    "all_images_train = {'KORA': [],\n",
    "             'NAKO': [],\n",
    "             'UKB' : []}\n",
    "all_pat_ids = {'KORA': [],\n",
    "             'NAKO': [],\n",
    "             'UKB' : []}\n",
    "for i, data_id in enumerate(['KORA']):\n",
    "    data_dir = os.path.join(root_dir, data_id, 'data')\n",
    "    filenames = os.path.join(root_dir, data_id, data_id+'.test')\n",
    "    # read filenames\n",
    "    with open(filenames) as f:\n",
    "        pat_ids = f.read().splitlines()   \n",
    "    all_pat_ids[data_id] = pat_ids\n",
    "\n",
    "    print(pat_ids)\n",
    "    for folder in pat_ids:\n",
    "        seg_dir = os.path.join(data_dir,folder)\n",
    "        #listFiles = os.listdir(seg_dir)\n",
    "        #seg_files = [f for f in listFiles if \"input_scan\" in f or 'combined_segmentation' in f]\n",
    "        try:\n",
    "            img = nibabel.load(os.path.join(seg_dir,'resampled_image.nii.gz'))\n",
    "            segm = nibabel.load(os.path.join(seg_dir,'resampled_segm.nii.gz'))\n",
    "        except FileNotFoundError as err:\n",
    "            print('did not find input scan AND segmentation for patient id: ', folder)\n",
    "            print(err)\n",
    "        \n",
    "        all_images_train[data_id].append((img,segm))\n",
    "#print(all_images_train)\n",
    "print(all_pat_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min max normalization for each dataset separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KORA\n",
      "NAKO\n",
      "UKB\n"
     ]
    }
   ],
   "source": [
    "for i, data_id in enumerate(['KORA', 'NAKO', 'UKB']):\n",
    "    print(data_id)\n",
    "    images = all_images_train[data_id]\n",
    "    \n",
    "    for j, imgs in enumerate(images):\n",
    "        img = imgs[0].get_fdata()\n",
    "        img_header = imgs[0].header\n",
    "        \n",
    "        img_min = np.min(img)\n",
    "        img_max = np.max(img)\n",
    "        img = (img - img_min)/(img_max -img_min)\n",
    "                \n",
    "        new_img_nii = nibabel.Nifti1Image(img, img_header.get_best_affine(), img_header)        \n",
    "        new_file_path = os.path.join(root_dir,data_id,'data', all_pat_ids[data_id][j],'resampled_normalized_image.nii.gz')\n",
    "        nibabel.save(new_img_nii, new_file_path)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate as si\n",
    "\n",
    "def do_interpolate(source, steps, header, target_voxel_dim, is_label=False):\n",
    "    x, y, z = [steps[k] * np.arange(source.shape[k]) for k in range(3)]\n",
    "    #print('x ', x)\n",
    "    #print('y ', y)\n",
    "    #print('z ', z)\n",
    "    \n",
    "    if is_label:\n",
    "        method = 'nearest'\n",
    "    else:\n",
    "        method = 'linear'\n",
    "\n",
    "    f = si.RegularGridInterpolator((x, y, z), source, method=method)\n",
    "\n",
    "    dx, dy, dz = target_voxel_dim\n",
    "    affine = header.get_best_affine()\n",
    "    np.fill_diagonal(affine, target_voxel_dim + [1])\n",
    "    header.set_sform(affine)\n",
    "    new_grid = np.mgrid[0:x[-1]:dx, 0:y[-1]:dy, 0:z[-1]:dz]\n",
    "    new_grid = np.moveaxis(new_grid, (0, 1, 2, 3), (3, 0, 1, 2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    interpolated = f(new_grid)\n",
    "    \n",
    "   \n",
    "    if is_label:\n",
    "        #print(np.unique(interpolated))\n",
    "        #print(np.mean(interpolated))\n",
    "        #print(np.max(interpolated))\n",
    "        #print('3s ', np.sum(interpolated ==3.98))\n",
    "        \n",
    "        #print('kidney l ', interpolated[56,68,34])\n",
    "        #print(np.where(interpolated==4))\n",
    "        interpolated = np.round(interpolated)\n",
    "        #print('rounded')\n",
    "        #print('kidney l ', interpolated[56,68,34])\n",
    "\n",
    "        #print('3s ', np.sum(interpolated ==3.98))\n",
    "        #interpolated = interpolated.astype('int')\n",
    "        #print('3s ', np.sum(interpolated ==3))\n",
    "\n",
    "    return interpolated, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(source_num_arr, target_array=np.arange(0, 500, 16)):\n",
    "    array = np.asarray(target_array)\n",
    "    idxs = [(np.abs(array - source_num)).argmin() for source_num in source_num_arr]\n",
    "    return [array[idx + 1] for idx in idxs]\n",
    "\n",
    "\n",
    "def post_interpolate(volume, labelmap=None, target_shape=None):\n",
    "    volume = do_cropping(volume, target_shape)\n",
    "    if labelmap is not None:\n",
    "        labelmap = do_cropping(labelmap, target_shape)\n",
    "    current_shape = volume.shape\n",
    "    intended_shape_deficit = target_shape - np.asarray(current_shape)\n",
    "\n",
    "    paddings = [tuple(\n",
    "        np.array([np.ceil((pad_tuples / 2) - pad_tuples % 2), np.floor((pad_tuples / 2) + pad_tuples % 2)]).astype(\n",
    "            'int32')) for pad_tuples in intended_shape_deficit]\n",
    "    paddings = tuple(paddings)\n",
    "\n",
    "    volume = np.pad(volume, paddings, mode='constant')\n",
    "    if labelmap is not None:\n",
    "        labelmap = np.pad(labelmap, paddings, mode='constant')\n",
    "\n",
    "    return volume, labelmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def do_cropping(source_num_arr, bounding):\n",
    "    start = list(map(lambda a, da: a // 2 - da // 2, source_num_arr.shape, bounding))\n",
    "    end = list(map(operator.add, start, bounding))\n",
    "    for i, val in enumerate(zip(start, end)):\n",
    "        if val[0] < 0:\n",
    "            start[i] = 0\n",
    "            end[i] = source_num_arr.shape[i]\n",
    "    slices = tuple(map(slice, tuple(start), tuple(end)))\n",
    "    return source_num_arr[slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
